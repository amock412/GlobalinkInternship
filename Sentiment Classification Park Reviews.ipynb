{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Classification of Park Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parkReviews = pd.read_csv('allEnReviews.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_for</th>\n",
       "      <th>review_id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_url</th>\n",
       "      <th>published</th>\n",
       "      <th>date_retrieved</th>\n",
       "      <th>num_stars</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNpeGF6TTNnRRAB</td>\n",
       "      <td>Claudia</td>\n",
       "      <td>https://www.google.com/maps/contrib/1001449741...</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.211296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>One of the nicest entry points to this invitin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURDOGEyMGpnRRAB</td>\n",
       "      <td>Nate Neel</td>\n",
       "      <td>https://www.google.com/maps/contrib/1121030547...</td>\n",
       "      <td>8 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.212245</td>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Waterfront to fish or just relax, great place ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUM4Nk9Ya3lnRRAB</td>\n",
       "      <td>Yucel Salimoglu</td>\n",
       "      <td>https://www.google.com/maps/contrib/1034180738...</td>\n",
       "      <td>11 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.213178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Everything except the parking is good here.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNVdWNUbE9REAE</td>\n",
       "      <td>COCO BEADZ</td>\n",
       "      <td>https://www.google.com/maps/contrib/1036060504...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.214115</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>Defenely the best park in Montreal East, Tetre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUMwdHJDTm1nRRAB</td>\n",
       "      <td>Anna Maria Fiore</td>\n",
       "      <td>https://www.google.com/maps/contrib/1016779009...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.215069</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>It's so peaceful and happy place near the water</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         review_for                             review_id  \\\n",
       "0  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUNpeGF6TTNnRRAB   \n",
       "1  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSURDOGEyMGpnRRAB   \n",
       "2  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUM4Nk9Ya3lnRRAB   \n",
       "3  Parc de la Capture-d'Ethan-Allen   ChZDSUhNMG9nS0VJQ0FnSUNVdWNUbE9REAE   \n",
       "4  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUMwdHJDTm1nRRAB   \n",
       "\n",
       "           username                                           user_url  \\\n",
       "0           Claudia  https://www.google.com/maps/contrib/1001449741...   \n",
       "1         Nate Neel  https://www.google.com/maps/contrib/1121030547...   \n",
       "2   Yucel Salimoglu  https://www.google.com/maps/contrib/1034180738...   \n",
       "3        COCO BEADZ  https://www.google.com/maps/contrib/1036060504...   \n",
       "4  Anna Maria Fiore  https://www.google.com/maps/contrib/1016779009...   \n",
       "\n",
       "       published              date_retrieved  num_stars  num_reviews  \\\n",
       "0   7 months ago  2021-06-20 22:04:09.211296        4.0        107.0   \n",
       "1   8 months ago  2021-06-20 22:04:09.212245        5.0        121.0   \n",
       "2  11 months ago  2021-06-20 22:04:09.213178        4.0         79.0   \n",
       "3     a year ago  2021-06-20 22:04:09.214115        4.0        128.0   \n",
       "4     a year ago  2021-06-20 22:04:09.215069        5.0         39.0   \n",
       "\n",
       "                                         review_text  label  \n",
       "0  One of the nicest entry points to this invitin...      1  \n",
       "1  Waterfront to fish or just relax, great place ...      1  \n",
       "2        Everything except the parking is good here.      1  \n",
       "3  Defenely the best park in Montreal East, Tetre...      1  \n",
       "4    It's so peaceful and happy place near the water      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_for</th>\n",
       "      <th>review_id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_url</th>\n",
       "      <th>published</th>\n",
       "      <th>date_retrieved</th>\n",
       "      <th>num_stars</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>uppercase_char_count</th>\n",
       "      <th>special_char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNnd0xqYmhnRRAB</td>\n",
       "      <td>Marc-André Maurice</td>\n",
       "      <td>https://www.google.com/maps/contrib/1054968570...</td>\n",
       "      <td>4 years ago</td>\n",
       "      <td>2021-06-20 22:04:09.223866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>If you want to have a beer by the St-Laurence ...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURnd2R1bW5nRRAB</td>\n",
       "      <td>Carismé Pierre</td>\n",
       "      <td>https://www.google.com/maps/contrib/1056897378...</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>2021-06-20 22:04:09.225823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Correct...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNxMWM2bVFREAE</td>\n",
       "      <td>Steve Huard</td>\n",
       "      <td>https://www.google.com/maps/contrib/1165278777...</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>2021-06-20 22:04:09.228581</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Très beau mes j'aimerais pouvoir descendre au ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Parc Mohawk</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNpbVB6SjJBRRAB</td>\n",
       "      <td>Miguel Veliz</td>\n",
       "      <td>https://www.google.com/maps/contrib/1101192075...</td>\n",
       "      <td>8 months ago</td>\n",
       "      <td>2021-06-22 11:54:53.183611</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Field is uneven, represents risks for players....</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Parc Mohawk</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUM0bVBIazB3RRAB</td>\n",
       "      <td>Fonaq</td>\n",
       "      <td>https://www.google.com/maps/contrib/1076101585...</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>2021-06-22 11:54:53.191064</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Great place to go play tennis, soccer or half ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41749</th>\n",
       "      <td>Square Dézéry</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURDbU9lRnhnRRAB</td>\n",
       "      <td>Andre Gagnon</td>\n",
       "      <td>https://www.google.com/maps/contrib/1019125653...</td>\n",
       "      <td>9 months ago</td>\n",
       "      <td>2021-06-22 20:31:39.563398</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Too many itinerants next to Notre Dame campsite</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41758</th>\n",
       "      <td>Square Dézéry</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNRMW8tbXRBRRAB</td>\n",
       "      <td>Francis Tanguay</td>\n",
       "      <td>https://www.google.com/maps/contrib/1170721416...</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>2021-06-22 20:31:39.573976</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>A little too expensive for some article but ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41761</th>\n",
       "      <td>Square Dézéry</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURRMU1fM3pBRRAB</td>\n",
       "      <td>Johanne gauvreau</td>\n",
       "      <td>https://www.google.com/maps/contrib/1162172471...</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>2021-06-22 20:31:39.580552</td>\n",
       "      <td>3.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Very good xx</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41783</th>\n",
       "      <td>Parc Paul-Séguin</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURnLS16Um93RRAB</td>\n",
       "      <td>Denise Le Blanc</td>\n",
       "      <td>https://www.google.com/maps/contrib/1040043322...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-23 16:12:02.475158</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>A small park ideal for young families, games, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41818</th>\n",
       "      <td>Parc Pierre-Boucher</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUM4Z2ZlUnR3RRAB</td>\n",
       "      <td>Martin Coursol</td>\n",
       "      <td>https://www.google.com/maps/contrib/1106775382...</td>\n",
       "      <td>11 months ago</td>\n",
       "      <td>2021-06-24 14:29:09.681038</td>\n",
       "      <td>3.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>Small park limited to a few benches. Perfect f...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3312 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review_for                             review_id  \\\n",
       "13     Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUNnd0xqYmhnRRAB   \n",
       "15     Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSURnd2R1bW5nRRAB   \n",
       "18     Parc de la Capture-d'Ethan-Allen   ChZDSUhNMG9nS0VJQ0FnSUNxMWM2bVFREAE   \n",
       "121                         Parc Mohawk  ChdDSUhNMG9nS0VJQ0FnSUNpbVB6SjJBRRAB   \n",
       "124                         Parc Mohawk  ChdDSUhNMG9nS0VJQ0FnSUM0bVBIazB3RRAB   \n",
       "...                                 ...                                   ...   \n",
       "41749                     Square Dézéry  ChdDSUhNMG9nS0VJQ0FnSURDbU9lRnhnRRAB   \n",
       "41758                     Square Dézéry  ChdDSUhNMG9nS0VJQ0FnSUNRMW8tbXRBRRAB   \n",
       "41761                     Square Dézéry  ChdDSUhNMG9nS0VJQ0FnSURRMU1fM3pBRRAB   \n",
       "41783                  Parc Paul-Séguin  ChdDSUhNMG9nS0VJQ0FnSURnLS16Um93RRAB   \n",
       "41818               Parc Pierre-Boucher  ChdDSUhNMG9nS0VJQ0FnSUM4Z2ZlUnR3RRAB   \n",
       "\n",
       "                 username                                           user_url  \\\n",
       "13     Marc-André Maurice  https://www.google.com/maps/contrib/1054968570...   \n",
       "15         Carismé Pierre  https://www.google.com/maps/contrib/1056897378...   \n",
       "18            Steve Huard  https://www.google.com/maps/contrib/1165278777...   \n",
       "121          Miguel Veliz  https://www.google.com/maps/contrib/1101192075...   \n",
       "124                 Fonaq  https://www.google.com/maps/contrib/1076101585...   \n",
       "...                   ...                                                ...   \n",
       "41749        Andre Gagnon  https://www.google.com/maps/contrib/1019125653...   \n",
       "41758     Francis Tanguay  https://www.google.com/maps/contrib/1170721416...   \n",
       "41761    Johanne gauvreau  https://www.google.com/maps/contrib/1162172471...   \n",
       "41783     Denise Le Blanc  https://www.google.com/maps/contrib/1040043322...   \n",
       "41818      Martin Coursol  https://www.google.com/maps/contrib/1106775382...   \n",
       "\n",
       "           published              date_retrieved  num_stars  num_reviews  \\\n",
       "13       4 years ago  2021-06-20 22:04:09.223866        3.0         32.0   \n",
       "15       3 years ago  2021-06-20 22:04:09.225823        3.0         97.0   \n",
       "18        6 days ago  2021-06-20 22:04:09.228581        3.0          3.0   \n",
       "121     8 months ago  2021-06-22 11:54:53.183611        3.0         61.0   \n",
       "124      2 years ago  2021-06-22 11:54:53.191064        3.0         17.0   \n",
       "...              ...                         ...        ...          ...   \n",
       "41749   9 months ago  2021-06-22 20:31:39.563398        3.0         72.0   \n",
       "41758    3 years ago  2021-06-22 20:31:39.573976        3.0         18.0   \n",
       "41761    3 years ago  2021-06-22 20:31:39.580552        3.0        139.0   \n",
       "41783     a year ago  2021-06-23 16:12:02.475158        3.0         12.0   \n",
       "41818  11 months ago  2021-06-24 14:29:09.681038        3.0        116.0   \n",
       "\n",
       "                                             review_text  label  word_count  \\\n",
       "13     If you want to have a beer by the St-Laurence ...      0          12   \n",
       "15                                            Correct...      0           1   \n",
       "18     Très beau mes j'aimerais pouvoir descendre au ...      0          21   \n",
       "121    Field is uneven, represents risks for players....      0          20   \n",
       "124    Great place to go play tennis, soccer or half ...      0          11   \n",
       "...                                                  ...    ...         ...   \n",
       "41749    Too many itinerants next to Notre Dame campsite      0           8   \n",
       "41758  A little too expensive for some article but ve...      0          11   \n",
       "41761                                       Very good xx      0           3   \n",
       "41783  A small park ideal for young families, games, ...      0          13   \n",
       "41818  Small park limited to a few benches. Perfect f...      0          19   \n",
       "\n",
       "       uppercase_char_count  special_char_count  \n",
       "13                        3                   1  \n",
       "15                        1                   3  \n",
       "18                        1                   3  \n",
       "121                       4                   5  \n",
       "124                       1                   2  \n",
       "...                     ...                 ...  \n",
       "41749                     3                   0  \n",
       "41758                     1                   1  \n",
       "41761                     1                   0  \n",
       "41783                     2                   4  \n",
       "41818                     2                   3  \n",
       "\n",
       "[3312 rows x 13 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkReviews[parkReviews['num_stars'] == 3.0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating summary statistics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "parkReviews['word_count'] = [len(review.split()) for review in parkReviews['review_text']]\n",
    "\n",
    "parkReviews['uppercase_char_count'] = [sum(char.isupper() for char in review) \\\n",
    "                              for review in parkReviews['review_text']]                           \n",
    "\n",
    "parkReviews['special_char_count'] = [sum(char in string.punctuation for char in review) \\\n",
    "                            for review in parkReviews['review_text']]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_reviews = parkReviews[parkReviews['label'] == 1]\n",
    "neg_reviews = parkReviews[parkReviews['label'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After breaking down the dataset into positive and negative reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36920.000000\n",
       "mean        13.435049\n",
       "std         17.949938\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          8.000000\n",
       "75%         16.000000\n",
       "max        634.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4902.000000\n",
       "mean       15.740718\n",
       "std        21.407586\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         9.000000\n",
       "75%        19.000000\n",
       "max       490.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviews['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8827889627468797"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36920/(4902 + 36920)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compare the number of uppercase letters used in the postive and negative reviews. As we can see there is no real difference between the two. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36920.000000\n",
       "mean         2.075433\n",
       "std          3.525758\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          2.000000\n",
       "max        259.000000\n",
       "Name: uppercase_char_count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews['uppercase_char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4902.000000\n",
       "mean        2.157487\n",
       "std         3.377507\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        87.000000\n",
       "Name: uppercase_char_count, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviews['uppercase_char_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's take a look at the special characters present in the positive and negativve group of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36920.000000\n",
       "mean         2.111430\n",
       "std          3.324735\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          3.000000\n",
       "max        135.000000\n",
       "Name: special_char_count, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews['special_char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4902.000000\n",
       "mean        2.436557\n",
       "std         4.232427\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         3.000000\n",
       "max       109.000000\n",
       "Name: special_char_count, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviews['special_char_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreamock/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostCommonWords(reviews, n_most_common, stopwords=None):\n",
    "\n",
    "    # flatten review column into a list of words, and set each to lowercase\n",
    "    flattened_reviews = [word for review in reviews for word in \\\n",
    "                         review.lower().split()]\n",
    "\n",
    "\n",
    "    # remove punctuation from reviews\n",
    "    flattened_reviews = [''.join(char for char in review if \\\n",
    "                                 char not in string.punctuation) for \\\n",
    "                         review in flattened_reviews]\n",
    "\n",
    "\n",
    "    # remove stopwords, if applicable\n",
    "    if stopwords:\n",
    "        flattened_reviews = [word for word in flattened_reviews if \\\n",
    "                             word not in stopwords]\n",
    "\n",
    "\n",
    "    # remove any empty strings that were created by this process\n",
    "    flattened_reviews = [review for review in flattened_reviews if review]\n",
    "\n",
    "    return Counter(flattened_reviews).most_common(n_most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 23250),\n",
       " ('a', 17043),\n",
       " ('and', 16999),\n",
       " ('park', 15169),\n",
       " ('to', 13713),\n",
       " ('for', 11101),\n",
       " ('of', 10785),\n",
       " ('place', 8822),\n",
       " ('in', 8482),\n",
       " ('nice', 8142),\n",
       " ('beautiful', 7812),\n",
       " ('is', 7354),\n",
       " ('very', 6595),\n",
       " ('with', 6271),\n",
       " ('great', 5028)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostCommonWords(pos_reviews['review_text'], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4240),\n",
       " ('a', 2299),\n",
       " ('and', 2045),\n",
       " ('to', 1913),\n",
       " ('park', 1826),\n",
       " ('of', 1594),\n",
       " ('is', 1485),\n",
       " ('for', 1299),\n",
       " ('in', 1109),\n",
       " ('not', 1039),\n",
       " ('it', 991),\n",
       " ('but', 943),\n",
       " ('there', 789),\n",
       " ('nice', 723),\n",
       " ('i', 701)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostCommonWords(neg_reviews['review_text'], 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common words involve a lot of common words. Therefore we will look at them without stopwords and determine the most common words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('park', 15169),\n",
       " ('place', 8822),\n",
       " ('nice', 8142),\n",
       " ('beautiful', 7812),\n",
       " ('great', 5028),\n",
       " ('good', 3680),\n",
       " ('kids', 2177),\n",
       " ('walk', 2147),\n",
       " ('montreal', 2019),\n",
       " ('water', 1977)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostCommonWords(pos_reviews['review_text'], 10, stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['park',\n",
       " 'place',\n",
       " 'nice',\n",
       " 'beautiful',\n",
       " 'great',\n",
       " 'good',\n",
       " 'kids',\n",
       " 'walk',\n",
       " 'montreal',\n",
       " 'water',\n",
       " 'well',\n",
       " 'summer',\n",
       " 'children',\n",
       " 'picnic',\n",
       " 'family']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[item for item, count in a ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('park', 1826),\n",
       " ('nice', 723),\n",
       " ('place', 686),\n",
       " ('beautiful', 446),\n",
       " ('good', 431),\n",
       " ('people', 357),\n",
       " ('small', 354),\n",
       " ('little', 301),\n",
       " ('children', 297),\n",
       " ('water', 277),\n",
       " ('kids', 261),\n",
       " ('many', 245),\n",
       " ('go', 233),\n",
       " ('great', 203),\n",
       " ('lot', 196)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostCommonWords(neg_reviews['review_text'], 15, stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=15)\n",
    "bow = vectorizer.fit_transform(list(parkReviews['review_text']))\n",
    "labels = parkReviews['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41822, 2127)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '15',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '25',\n",
       " '30',\n",
       " '45',\n",
       " '50',\n",
       " '67',\n",
       " 'abandoned',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'absolutely',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accommodate',\n",
       " 'according',\n",
       " 'across',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actually',\n",
       " 'adapted',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adjacent',\n",
       " 'adjusted',\n",
       " 'admire',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advantage',\n",
       " 'advise',\n",
       " 'affordable',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'ages',\n",
       " 'ago',\n",
       " 'air',\n",
       " 'alcohol',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'amenities',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'ample',\n",
       " 'amusement',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angrignon',\n",
       " 'angus',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anjou',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appointed',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'april',\n",
       " 'archery',\n",
       " 'architecture',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arena',\n",
       " 'around',\n",
       " 'arranged',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'art',\n",
       " 'artificial',\n",
       " 'artists',\n",
       " 'as',\n",
       " 'ask',\n",
       " 'asphalt',\n",
       " 'at',\n",
       " 'athletes',\n",
       " 'atmosphere',\n",
       " 'attached',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attraction',\n",
       " 'attractions',\n",
       " 'attractive',\n",
       " 'au',\n",
       " 'august',\n",
       " 'autumn',\n",
       " 'available',\n",
       " 'avec',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awsome',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'background',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bags',\n",
       " 'ball',\n",
       " 'balls',\n",
       " 'bank',\n",
       " 'banks',\n",
       " 'bar',\n",
       " 'barbecue',\n",
       " 'barbecues',\n",
       " 'barbeque',\n",
       " 'barely',\n",
       " 'bars',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'basic',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'bathing',\n",
       " 'bathroom',\n",
       " 'bathrooms',\n",
       " 'bbq',\n",
       " 'bbqs',\n",
       " 'bcp',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beau',\n",
       " 'beaucoup',\n",
       " 'beautiful',\n",
       " 'beautifull',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'beaver',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'before',\n",
       " 'beginning',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'belle',\n",
       " 'below',\n",
       " 'bench',\n",
       " 'benches',\n",
       " 'benefit',\n",
       " 'berri',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beware',\n",
       " 'bicycle',\n",
       " 'bicycles',\n",
       " 'bien',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bikes',\n",
       " 'biking',\n",
       " 'bin',\n",
       " 'bins',\n",
       " 'biosphere',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bixi',\n",
       " 'black',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blocks',\n",
       " 'blue',\n",
       " 'blvd',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'boats',\n",
       " 'bocce',\n",
       " 'body',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'books',\n",
       " 'boring',\n",
       " 'borough',\n",
       " 'botanical',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bottles',\n",
       " 'bottom',\n",
       " 'boulevard',\n",
       " 'bourassa',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'brand',\n",
       " 'bravo',\n",
       " 'break',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathtaking',\n",
       " 'breeze',\n",
       " 'bridge',\n",
       " 'bridges',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'broken',\n",
       " 'brought',\n",
       " 'bug',\n",
       " 'bugs',\n",
       " 'building',\n",
       " 'buildings',\n",
       " 'built',\n",
       " 'bunch',\n",
       " 'bus',\n",
       " 'buses',\n",
       " 'business',\n",
       " 'bustle',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butts',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cafe',\n",
       " 'cafes',\n",
       " 'café',\n",
       " 'calisthenics',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calm',\n",
       " 'calming',\n",
       " 'came',\n",
       " 'camp',\n",
       " 'camping',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'canal',\n",
       " 'cannot',\n",
       " 'cans',\n",
       " 'cap',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'careful',\n",
       " 'cars',\n",
       " 'cartier',\n",
       " 'case',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catherine',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'ce',\n",
       " 'celebrate',\n",
       " 'center',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chair',\n",
       " 'chairs',\n",
       " 'chalet',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'charcoal',\n",
       " 'charge',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'chemical',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'chilling',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'christmas',\n",
       " 'church',\n",
       " 'cigarette',\n",
       " 'circuit',\n",
       " 'circus',\n",
       " 'cirque',\n",
       " 'citizens',\n",
       " 'city',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'cleaned',\n",
       " 'cleaner',\n",
       " 'cleaning',\n",
       " 'cleanliness',\n",
       " 'clear',\n",
       " 'cleared',\n",
       " 'clearly',\n",
       " 'climb',\n",
       " 'climbing',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'club',\n",
       " 'coast',\n",
       " 'coffee',\n",
       " 'cohen',\n",
       " 'cold',\n",
       " 'color',\n",
       " 'colorful',\n",
       " 'colors',\n",
       " 'colours',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'commercial',\n",
       " 'common',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compared',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'concept',\n",
       " 'concert',\n",
       " 'concerts',\n",
       " 'concrete',\n",
       " 'condition',\n",
       " 'congratulations',\n",
       " 'cons',\n",
       " 'considering',\n",
       " 'constantly',\n",
       " 'construction',\n",
       " 'contact',\n",
       " 'contains',\n",
       " 'contemplate',\n",
       " 'continue',\n",
       " 'convenience',\n",
       " 'convenient',\n",
       " 'cool',\n",
       " 'corner',\n",
       " 'corners',\n",
       " 'correct',\n",
       " 'cost',\n",
       " 'cote',\n",
       " 'cottage',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'country',\n",
       " 'countryside',\n",
       " 'couple',\n",
       " 'couples',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courteous',\n",
       " 'courts',\n",
       " 'cover',\n",
       " 'covered',\n",
       " 'covid',\n",
       " 'covid19',\n",
       " 'cozy',\n",
       " 'crack',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'create',\n",
       " 'created',\n",
       " 'cricket',\n",
       " 'cross',\n",
       " 'crosses',\n",
       " 'crossing',\n",
       " 'crowd',\n",
       " 'crowded',\n",
       " 'crowds',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'cup',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cycle',\n",
       " 'cycling',\n",
       " 'cyclists',\n",
       " 'côte',\n",
       " 'daily',\n",
       " 'damaged',\n",
       " 'dame',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dangerous',\n",
       " 'dans',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'daughters',\n",
       " 'day',\n",
       " 'daycare',\n",
       " 'days',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'decent',\n",
       " 'decided',\n",
       " 'dedicated',\n",
       " 'deep',\n",
       " 'deer',\n",
       " 'definitely',\n",
       " 'delicious',\n",
       " 'denis',\n",
       " 'depending',\n",
       " 'des',\n",
       " 'deserves',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'desired',\n",
       " 'despite',\n",
       " 'destination',\n",
       " 'destroyed',\n",
       " 'detour',\n",
       " 'development',\n",
       " 'diamond',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'dirt',\n",
       " 'dirty',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'discover',\n",
       " 'discovered',\n",
       " 'discovery',\n",
       " 'disgusting',\n",
       " 'distance',\n",
       " 'distancing',\n",
       " 'district',\n",
       " 'disturbing',\n",
       " 'diverse',\n",
       " 'diversity',\n",
       " 'divided',\n",
       " 'dj',\n",
       " 'do',\n",
       " 'dock',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'dog',\n",
       " 'doggy',\n",
       " 'dogs',\n",
       " 'doing',\n",
       " 'dollars',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'doors',\n",
       " 'down',\n",
       " 'downside',\n",
       " 'downtown',\n",
       " 'drapeau',\n",
       " 'dream',\n",
       " 'drink',\n",
       " 'drinking',\n",
       " 'drinks',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'drunk',\n",
       " 'dry',\n",
       " 'du',\n",
       " 'duck',\n",
       " 'ducks',\n",
       " 'due',\n",
       " 'dump',\n",
       " 'during',\n",
       " 'each',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'eau',\n",
       " 'ect',\n",
       " 'edge',\n",
       " 'effort',\n",
       " 'either',\n",
       " 'elderly',\n",
       " 'electric',\n",
       " 'electronic',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'employees',\n",
       " 'empty',\n",
       " 'en',\n",
       " 'enchanting',\n",
       " 'enclosed',\n",
       " 'end',\n",
       " 'endroit',\n",
       " 'ends',\n",
       " 'energy',\n",
       " 'enfants',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entertaining',\n",
       " 'entertainment',\n",
       " 'entire',\n",
       " 'entrance',\n",
       " 'entry',\n",
       " 'environment',\n",
       " 'equipment',\n",
       " 'equipped',\n",
       " 'escape',\n",
       " 'especially',\n",
       " 'essential',\n",
       " 'est',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'european',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'evenings',\n",
       " 'event',\n",
       " 'events',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyday',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'exceptional',\n",
       " 'exciting',\n",
       " 'exercise',\n",
       " 'exercises',\n",
       " 'exercising',\n",
       " 'exists',\n",
       " 'expect',\n",
       " 'expected',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'explore',\n",
       " 'exploring',\n",
       " 'exposed',\n",
       " 'extra',\n",
       " 'extraordinary',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'fabulous',\n",
       " 'face',\n",
       " 'facilities',\n",
       " 'facility',\n",
       " 'facing',\n",
       " 'fact',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'fall',\n",
       " 'falls',\n",
       " 'families',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'farm',\n",
       " 'fast',\n",
       " 'fauna',\n",
       " 'favorite',\n",
       " 'favourite',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'fee',\n",
       " 'feed',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'felt',\n",
       " 'fence',\n",
       " 'fenced',\n",
       " 'fences',\n",
       " 'festival',\n",
       " 'festivals',\n",
       " 'festive',\n",
       " 'few',\n",
       " 'fi',\n",
       " 'field',\n",
       " 'fields',\n",
       " 'fill',\n",
       " 'filled',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'fire',\n",
       " 'fireworks',\n",
       " 'first',\n",
       " 'fish',\n",
       " 'fishing',\n",
       " 'fit',\n",
       " 'fitness',\n",
       " 'five',\n",
       " 'fixed',\n",
       " 'flat',\n",
       " 'flooded',\n",
       " 'floor',\n",
       " 'flora',\n",
       " 'flow',\n",
       " 'flower',\n",
       " 'flowers',\n",
       " 'fly',\n",
       " 'flying',\n",
       " 'foliage',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'fontaine',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'football',\n",
       " 'footbridge',\n",
       " 'for',\n",
       " 'forest',\n",
       " 'forget',\n",
       " 'form',\n",
       " 'former',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'fountain',\n",
       " 'fountains',\n",
       " 'four',\n",
       " 'free',\n",
       " 'french',\n",
       " 'frequent',\n",
       " 'frequented',\n",
       " 'frequently',\n",
       " 'fresh',\n",
       " 'freshness',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'frisbee',\n",
       " 'from',\n",
       " 'front',\n",
       " 'frozen',\n",
       " 'full',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'functional',\n",
       " 'funny',\n",
       " 'further',\n",
       " 'future',\n",
       " 'game',\n",
       " 'gamelin',\n",
       " 'games',\n",
       " 'garbage',\n",
       " 'garden',\n",
       " 'gardens',\n",
       " 'gas',\n",
       " 'gather',\n",
       " 'gathering',\n",
       " 'gatherings',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'gazebo',\n",
       " 'geese',\n",
       " 'gem',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'get',\n",
       " 'getaway',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'giant',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'glass',\n",
       " 'go',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'golf',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'google',\n",
       " 'goose',\n",
       " 'gorgeous',\n",
       " 'got',\n",
       " 'gouin',\n",
       " 'grab',\n",
       " 'grand',\n",
       " 'grass',\n",
       " 'grassy',\n",
       " 'gravel',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greatly',\n",
       " 'green',\n",
       " 'greenery',\n",
       " 'grew',\n",
       " 'grills',\n",
       " 'grocery',\n",
       " 'groomed',\n",
       " 'ground',\n",
       " 'grounds',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'growing',\n",
       " 'grown',\n",
       " 'guess',\n",
       " 'guide',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gym',\n",
       " 'had',\n",
       " 'half',\n",
       " 'hall',\n",
       " 'hammock',\n",
       " 'hammocks',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'handsome',\n",
       " 'hang',\n",
       " 'hanging',\n",
       " 'hangout',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happens',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'health',\n",
       " 'healthy',\n",
       " 'hear',\n",
       " 'heart',\n",
       " 'heat',\n",
       " 'heated',\n",
       " 'heaven',\n",
       " 'heavy',\n",
       " 'height',\n",
       " 'held',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'henri',\n",
       " 'her',\n",
       " 'here',\n",
       " 'heritage',\n",
       " 'hey',\n",
       " 'hidden',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'highway',\n",
       " 'hike',\n",
       " 'hikes',\n",
       " 'hiking',\n",
       " 'hill',\n",
       " 'hills',\n",
       " 'him',\n",
       " 'his',\n",
       " 'historic',\n",
       " 'historical',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hochelaga',\n",
       " 'hockey',\n",
       " 'hold',\n",
       " 'hole',\n",
       " 'holes',\n",
       " 'home',\n",
       " 'homeless',\n",
       " 'homes',\n",
       " 'hope',\n",
       " 'horrible',\n",
       " 'host',\n",
       " 'hosts',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'houses',\n",
       " 'how',\n",
       " 'however',\n",
       " 'huge',\n",
       " 'human',\n",
       " 'humans',\n",
       " 'hustle',\n",
       " 'ice',\n",
       " 'iconic',\n",
       " 'icy',\n",
       " 'idea',\n",
       " 'ideal',\n",
       " 'if',\n",
       " 'il',\n",
       " 'ile',\n",
       " 'imagine',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'impressed',\n",
       " 'impression',\n",
       " 'impressive',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'in',\n",
       " 'includes',\n",
       " 'including',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'indoor',\n",
       " 'industrial',\n",
       " 'information',\n",
       " 'infrastructure',\n",
       " 'inner',\n",
       " 'insects',\n",
       " 'inside',\n",
       " 'install',\n",
       " 'installation',\n",
       " 'installations',\n",
       " 'installed',\n",
       " 'instead',\n",
       " 'interest',\n",
       " 'interesting',\n",
       " 'internet',\n",
       " 'intimate',\n",
       " 'into',\n",
       " 'inviting',\n",
       " 'is',\n",
       " 'island',\n",
       " 'islands',\n",
       " 'isn',\n",
       " 'issue',\n",
       " 'it',\n",
       " 'italian',\n",
       " 'italy',\n",
       " 'items',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'jacques',\n",
       " 'jarry',\n",
       " 'jean',\n",
       " 'jet',\n",
       " 'jets',\n",
       " 'jeux',\n",
       " 'jewel',\n",
       " 'job',\n",
       " 'jog',\n",
       " 'joggers',\n",
       " 'jogging',\n",
       " 'joseph',\n",
       " 'joy',\n",
       " 'july',\n",
       " 'june',\n",
       " 'jungle',\n",
       " 'junkies',\n",
       " 'just',\n",
       " 'kayak',\n",
       " 'keep',\n",
       " 'keeping',\n",
       " 'kept',\n",
       " 'kick',\n",
       " 'kid',\n",
       " 'kiddie',\n",
       " 'kids',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'kinds',\n",
       " 'kiosk',\n",
       " 'kite',\n",
       " 'km',\n",
       " 'know',\n",
       " 'known',\n",
       " 'la',\n",
       " 'lac',\n",
       " 'lachine',\n",
       " 'lack',\n",
       " 'lacking',\n",
       " 'lacks',\n",
       " 'lady',\n",
       " 'lafontaine',\n",
       " 'laid',\n",
       " 'lake',\n",
       " 'lakes',\n",
       " 'land',\n",
       " 'landscape',\n",
       " 'landscaped',\n",
       " 'landscapes',\n",
       " 'landscaping',\n",
       " 'lane',\n",
       " 'lanes',\n",
       " 'large',\n",
       " 'larger',\n",
       " 'largest',\n",
       " 'lasalle',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'laurence',\n",
       " 'laurent',\n",
       " 'laurier',\n",
       " 'laval',\n",
       " 'lawn',\n",
       " 'lawns',\n",
       " 'lawrence',\n",
       " 'lay',\n",
       " 'layout',\n",
       " 'le',\n",
       " 'leading',\n",
       " ...]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2127"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfDict = dict(zip(vectorizer.get_feature_names(), bow.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2007442684284577"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfDict['appreciated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDf = pd.DataFrame.from_dict(tfidfDict, \n",
    "                                   orient='index', columns=['tfidf'])\n",
    "featureDf.reset_index(inplace=True)\n",
    "featureDf = featureDf.rename(columns = {'index':'feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>today</td>\n",
       "      <td>0.183384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>0.190613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>nicest</td>\n",
       "      <td>0.196902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>pandemic</td>\n",
       "      <td>0.199586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>appreciated</td>\n",
       "      <td>0.200744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>points</td>\n",
       "      <td>0.208271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>promenade</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>mask</td>\n",
       "      <td>0.220245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>entry</td>\n",
       "      <td>0.221551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>inviting</td>\n",
       "      <td>0.222929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature     tfidf\n",
       "1895        today  0.183384\n",
       "575     enjoyable  0.190613\n",
       "1214       nicest  0.196902\n",
       "1302     pandemic  0.199586\n",
       "105   appreciated  0.200744\n",
       "1397       points  0.208271\n",
       "1445    promenade  0.215600\n",
       "1101         mask  0.220245\n",
       "584         entry  0.221551\n",
       "918      inviting  0.222929"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureDf.sort_values('tfidf')[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the words that have the highest tfidf score in the positive and negative sentiment datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_pos = TfidfVectorizer(min_df=15)\n",
    "bow_pos = vectorizer_pos.fit_transform(list(pos_reviews['review_text']))\n",
    "labels_pos = pos_reviews['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_neg = TfidfVectorizer(min_df=15)\n",
    "bow_neg = vectorizer_neg.fit_transform(list(neg_reviews['review_text']))\n",
    "labels_neg = neg_reviews['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfDictPos = dict(zip(vectorizer_pos.get_feature_names(), bow_pos.toarray()[0]))\n",
    "tfidfDictNeg = dict(zip(vectorizer_neg.get_feature_names(), bow_neg.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "posFeatureDf = pd.DataFrame.from_dict(tfidfDictPos, \n",
    "                                   orient='index', columns=['tfidf'])\n",
    "posFeatureDf.reset_index(inplace=True)\n",
    "posFeatureDf = posFeatureDf.rename(columns = {'index':'feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "negFeatureDf = pd.DataFrame.from_dict(tfidfDictNeg, \n",
    "                                   orient='index', columns=['tfidf'])\n",
    "negFeatureDf.reset_index(inplace=True)\n",
    "negFeatureDf = negFeatureDf.rename(columns = {'index':'feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>the</td>\n",
       "      <td>0.175157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>toilet</td>\n",
       "      <td>0.178911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>chalet</td>\n",
       "      <td>0.183008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>forget</td>\n",
       "      <td>0.184969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>lawrence</td>\n",
       "      <td>0.187326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>offers</td>\n",
       "      <td>0.188328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>0.196256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>this</td>\n",
       "      <td>0.198067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>today</td>\n",
       "      <td>0.201076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>0.202747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>nicest</td>\n",
       "      <td>0.210674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>appreciated</td>\n",
       "      <td>0.217112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>pandemic</td>\n",
       "      <td>0.218602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>points</td>\n",
       "      <td>0.222722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>promenade</td>\n",
       "      <td>0.233454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature     tfidf\n",
       "1611          the  0.175157\n",
       "1643       toilet  0.178911\n",
       "284        chalet  0.183008\n",
       "605        forget  0.184969\n",
       "862      lawrence  0.187326\n",
       "1077       offers  0.188328\n",
       "1764   waterfront  0.196256\n",
       "1624         this  0.198067\n",
       "1639        today  0.201076\n",
       "492     enjoyable  0.202747\n",
       "1052       nicest  0.210674\n",
       "94    appreciated  0.217112\n",
       "1127     pandemic  0.218602\n",
       "1210       points  0.222722\n",
       "1244    promenade  0.233454"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posFeatureDf.sort_values('tfidf')[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>friendly</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>friends</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>from</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>free</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>the</td>\n",
       "      <td>0.127299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>to</td>\n",
       "      <td>0.154861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>you</td>\n",
       "      <td>0.243902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>have</td>\n",
       "      <td>0.251447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>if</td>\n",
       "      <td>0.277831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>by</td>\n",
       "      <td>0.282278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>ok</td>\n",
       "      <td>0.299108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>its</td>\n",
       "      <td>0.314444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>want</td>\n",
       "      <td>0.366955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>st</td>\n",
       "      <td>0.399077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>beer</td>\n",
       "      <td>0.444937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     tfidf\n",
       "188  friendly  0.000000\n",
       "189   friends  0.000000\n",
       "190      from  0.000000\n",
       "187      free  0.000000\n",
       "481       the  0.127299\n",
       "498        to  0.154861\n",
       "567       you  0.243902\n",
       "215      have  0.251447\n",
       "232        if  0.277831\n",
       "71         by  0.282278\n",
       "325        ok  0.299108\n",
       "242       its  0.314444\n",
       "531      want  0.366955\n",
       "454        st  0.399077\n",
       "52       beer  0.444937"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negFeatureDf.sort_values('tfidf')[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 200 best features \n",
    "selected_features = SelectKBest(chi2, k=200).fit(bow, labels).get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41822x200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use selected features for vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=15, vocabulary=selected_features)\n",
    "\n",
    "bow2 = vectorizer.fit_transform(list(parkReviews['review_text']))\n",
    "bow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20,\n",
       " 37,\n",
       " 76,\n",
       " 85,\n",
       " 93,\n",
       " 109,\n",
       " 124,\n",
       " 130,\n",
       " 140,\n",
       " 141,\n",
       " 143,\n",
       " 149,\n",
       " 150,\n",
       " 164,\n",
       " 173,\n",
       " 177,\n",
       " 182,\n",
       " 185,\n",
       " 201,\n",
       " 202,\n",
       " 215,\n",
       " 220,\n",
       " 238,\n",
       " 243,\n",
       " 262,\n",
       " 275,\n",
       " 295,\n",
       " 297,\n",
       " 299,\n",
       " 301,\n",
       " 343,\n",
       " 353,\n",
       " 355,\n",
       " 363,\n",
       " 383,\n",
       " 392,\n",
       " 396,\n",
       " 397,\n",
       " 407,\n",
       " 411,\n",
       " 436,\n",
       " 443,\n",
       " 450,\n",
       " 454,\n",
       " 464,\n",
       " 478,\n",
       " 486,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 500,\n",
       " 511,\n",
       " 512,\n",
       " 515,\n",
       " 518,\n",
       " 533,\n",
       " 534,\n",
       " 540,\n",
       " 541,\n",
       " 564,\n",
       " 574,\n",
       " 606,\n",
       " 608,\n",
       " 609,\n",
       " 618,\n",
       " 639,\n",
       " 684,\n",
       " 701,\n",
       " 721,\n",
       " 728,\n",
       " 729,\n",
       " 736,\n",
       " 748,\n",
       " 761,\n",
       " 767,\n",
       " 779,\n",
       " 788,\n",
       " 816,\n",
       " 821,\n",
       " 843,\n",
       " 861,\n",
       " 864,\n",
       " 873,\n",
       " 892,\n",
       " 913,\n",
       " 919,\n",
       " 922,\n",
       " 924,\n",
       " 929,\n",
       " 962,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 1004,\n",
       " 1005,\n",
       " 1007,\n",
       " 1011,\n",
       " 1062,\n",
       " 1063,\n",
       " 1064,\n",
       " 1077,\n",
       " 1082,\n",
       " 1092,\n",
       " 1101,\n",
       " 1148,\n",
       " 1152,\n",
       " 1158,\n",
       " 1174,\n",
       " 1192,\n",
       " 1198,\n",
       " 1200,\n",
       " 1206,\n",
       " 1211,\n",
       " 1219,\n",
       " 1220,\n",
       " 1221,\n",
       " 1222,\n",
       " 1226,\n",
       " 1228,\n",
       " 1246,\n",
       " 1248,\n",
       " 1249,\n",
       " 1258,\n",
       " 1271,\n",
       " 1292,\n",
       " 1301,\n",
       " 1309,\n",
       " 1331,\n",
       " 1336,\n",
       " 1338,\n",
       " 1355,\n",
       " 1374,\n",
       " 1399,\n",
       " 1405,\n",
       " 1406,\n",
       " 1407,\n",
       " 1418,\n",
       " 1434,\n",
       " 1441,\n",
       " 1453,\n",
       " 1473,\n",
       " 1498,\n",
       " 1501,\n",
       " 1504,\n",
       " 1509,\n",
       " 1567,\n",
       " 1640,\n",
       " 1670,\n",
       " 1686,\n",
       " 1688,\n",
       " 1689,\n",
       " 1690,\n",
       " 1692,\n",
       " 1725,\n",
       " 1759,\n",
       " 1769,\n",
       " 1814,\n",
       " 1815,\n",
       " 1816,\n",
       " 1858,\n",
       " 1861,\n",
       " 1862,\n",
       " 1863,\n",
       " 1867,\n",
       " 1871,\n",
       " 1899,\n",
       " 1900,\n",
       " 1901,\n",
       " 1903,\n",
       " 1918,\n",
       " 1929,\n",
       " 1953,\n",
       " 1955,\n",
       " 1958,\n",
       " 1962,\n",
       " 1970,\n",
       " 1971,\n",
       " 1985,\n",
       " 1991,\n",
       " 2006,\n",
       " 2020,\n",
       " 2024,\n",
       " 2025,\n",
       " 2038,\n",
       " 2043,\n",
       " 2049,\n",
       " 2054,\n",
       " 2067,\n",
       " 2069,\n",
       " 2083,\n",
       " 2085,\n",
       " 2088,\n",
       " 2096,\n",
       " 2102,\n",
       " 2103,\n",
       " 2106,\n",
       " 2107,\n",
       " 2108,\n",
       " 2109]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([20, 37, 76, 85, 93, 109, 124, 130, 140, 141, 143, 149, 150, 164, 173, 177, 182, 185, 201, 202, 215, 220, 238, 243, 262, 275, 295, 297, 299, 301, 343, 353, 355, 363, 383, 392, 396, 397, 407, 411, 436, 443, 450, 454, 464, 478, 486, 493, 494, 495, 496, 500, 511, 512, 515, 518, 533, 534, 540, 541, 564, 574, 606, 608, 609, 618, 639, 684, 701, 721, 728, 729, 736, 748, 761, 767, 779, 788, 816, 821, 843, 861, 864, 873, 892, 913, 919, 922, 924, 929, 962, 967, 968, 969, 1004, 1005, 1007, 1011, 1062, 1063, 1064, 1077, 1082, 1092, 1101, 1148, 1152, 1158, 1174, 1192, 1198, 1200, 1206, 1211, 1219, 1220, 1221, 1222, 1226, 1228, 1246, 1248, 1249, 1258, 1271, 1292, 1301, 1309, 1331, 1336, 1338, 1355, 1374, 1399, 1405, 1406, 1407, 1418, 1434, 1441, 1453, 1473, 1498, 1501, 1504, 1509, 1567, 1640, 1670, 1686, 1688, 1689, 1690, 1692, 1725, 1759, 1769, 1814, 1815, 1816, 1858, 1861, 1862, 1863, 1867, 1871, 1899, 1900, 1901, 1903, 1918, 1929, 1953, 1955, 1958, 1962, 1970, 1971, 1985, 1991, 2006, 2020, 2024, 2025, 2038, 2043, 2049, 2054, 2067, 2069, 2083, 2085, 2088, 2096, 2102, 2103, 2106, 2107, 2108, 2109])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.vocabulary_.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow, labels, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28020, 2127)\n",
      "(13802, 2127)\n",
      "(28020,)\n",
      "(13802,)\n"
     ]
    }
   ],
   "source": [
    "# check out the dataset \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Random Forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958846543979133"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = rfc()\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-154-61f989482ac5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrandom_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomizedSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    839\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1619\u001b[0m         evaluate_candidates(ParameterSampler(\n\u001b[1;32m   1620\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m             random_state=self.random_state))\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    807\u001b[0m                                    (split_idx, (train, test)) in product(\n\u001b[1;32m    808\u001b[0m                                    \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 809\u001b[0;31m                                    enumerate(cv.split(X, y, groups))))\n\u001b[0m\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classifier = rfc()\n",
    "\n",
    "hyperparameters = {\n",
    "    'n_estimators':stats.randint(10,300),\n",
    "    'criterion':['gini','entropy'],\n",
    "    'min_samples_split':stats.randint(2,9),\n",
    "    'bootstrap':[True,False]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(classifier, hyperparameters, n_iter=65, n_jobs=4)\n",
    "\n",
    "random_search.fit(bow, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_classifier = random_search.best_estimator_\n",
    "optimized_classifier.fit(X_train,y_train)\n",
    "\n",
    "optimized_classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(optimized_classifier.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(optimized_classifier.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking a look at classification errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-155-53e3cde6dadc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moptimized_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcorrectly_classified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mincorrectly_classified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    391\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     n_samples_bootstrap=n_samples_bootstrap)\n\u001b[0;32m--> 393\u001b[0;31m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0;31m# Collect newly grown trees\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    903\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    387\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimized_classifier.fit(X_train,y_train)\n",
    "\n",
    "correctly_classified = {}\n",
    "incorrectly_classified = {}\n",
    "\n",
    "for index, row in enumerate(X_test):\n",
    "    probability = optimized_classifier.predict_proba(row)\n",
    "\n",
    "    # get the location of the review in the dataframe\n",
    "    review_loc = y_test.index[index]\n",
    "\n",
    "    if optimized_classifier.predict(row) == y_test.iloc[index]:\n",
    "        correctly_classified[parkReviews['review_text'].loc[review_loc]] = probability\n",
    "    else:\n",
    "        incorrectly_classified[parkReviews['review_text'].iloc[review_loc]] = probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review, score in incorrectly_classified.items():\n",
    "    print('{}: {}'.format(review, score[0]))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for review, score in correctly_classified.items():\n",
    "    print('{}: {}'.format(review, score[0]))\n",
    "    print('-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " incorrectly_classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8871902622808289\n",
      "score on train: 0.9016773733047823\n",
      "CPU times: user 1 s, sys: 77.9 ms, total: 1.08 s\n",
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clfdt = DecisionTreeClassifier(min_samples_split=30,max_depth=10)\n",
    "clfdt.fit(X_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \"  + str(clfdt.score(X_test, y_test)))\n",
    "print(\"score on train: \" + str(clfdt.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8836400521663527\n",
      "score on train: 0.8860099928622412\n",
      "CPU times: user 1.61 s, sys: 125 ms, total: 1.73 s\n",
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bg=BaggingClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=3),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(X_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(bg.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(bg.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8921170844805101\n",
      "score on train: 0.9065310492505353\n"
     ]
    }
   ],
   "source": [
    "# boosting decision tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# setting \n",
    "# min_samples_split=10\n",
    "# max_depth=4\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),n_estimators=100,learning_rate=0.5)\n",
    "adb.fit(X_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(adb.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(adb.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x2127 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "- Naive Bayes: https://scikit-learn.org/stable/modules/naive_bayes.html\n",
    "- MultinomialNB: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 ms, sys: 35.7 ms, total: 55.5 ms\n",
      "Wall time: 299 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mnb = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8926242573540066\n",
      "score on train: 0.8975374732334047\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(mnb.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(mnb.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression \n",
    "\n",
    "Sklearn Documentation:\n",
    "\n",
    "- LogisticRegression: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "- SGD Classifier: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 333 ms, sys: 42.2 ms, total: 375 ms\n",
      "Wall time: 489 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr=LogisticRegression(max_iter=5000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8945080423127083\n",
      "score on train: 0.9053533190578158\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(lr.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(lr.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68 ms, sys: 5.54 ms, total: 73.5 ms\n",
      "Wall time: 83.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#logistic regression with stochastic gradient decent\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8908129256629475\n",
      "score on train: 0.8955745895788723\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(sgd.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(sgd.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8747283002463411\n",
      "score on train: 0.9011063526052819\n",
      "CPU times: user 2min 37s, sys: 3min 47s, total: 6min 25s\n",
      "Wall time: 20min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5,algorithm = 'ball_tree')\n",
    "knn = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(knn.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network pre-programmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras import losses\n",
    "from keras import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/4\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/input_spec.py:248 assert_input_compatibility  *\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 30 but received input with shape (None, 2127)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-179-4722136bbbed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_partial_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_partial_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_validation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1156\u001b[0m                 _r=1):\n\u001b[1;32m   1157\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1158\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1159\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:830 train_function  *\n        return step_function(self, iterator)\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:813 run_step  *\n        outputs = model.train_step(data)\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py:770 train_step  *\n        y_pred = self(x, training=True)\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/base_layer.py:989 __call__  *\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /opt/anaconda3/lib/python3.7/site-packages/keras/engine/input_spec.py:248 assert_input_compatibility  *\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_1 is incompatible with the layer: expected axis -1 of input shape to have value 30 but received input with shape (None, 2127)\n"
     ]
    }
   ],
   "source": [
    "# split an additional validation dataset\n",
    "X_validation=X_train[:100]\n",
    "X_partial_train=X_train[100:]\n",
    "y_validation=y_train[:100]\n",
    "y_partial_train=y_train[100:]\n",
    "model=models.Sequential()\n",
    "model.add(layers.Dense(16,activation='relu',input_shape=(30,)))\n",
    "model.add(layers.Dense(16,activation='relu'))\n",
    "model.add(layers.Dense(1,activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_partial_train,y_partial_train,epochs=4,batch_size=512,validation_data=(X_validation,y_validation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('')\n",
    "print(\"train shape: \" + str(x_train.shape))\n",
    "print(\"score on test: \" + str(model.evaluate(x_test,y_test)[1]))\n",
    "print(\"score on train: \"+ str(model.evaluate(x_train,y_train)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#allReviewEn[['']]\n",
    "\n",
    "train, test = train_test_split(allReviewEn, test_size = 0.3, random_state=42)\n",
    "\n",
    "# clean the indexing\n",
    "train.reset_index(drop=True),test.reset_index(drop=True)\n",
    "\n",
    "# save train and test in csv files \n",
    "train[['review_text', 'label']].to_csv('all_en_train.csv', index=False)\n",
    "test[['review_text', 'label']].to_csv('all_en_test.csv', index=False)\n",
    "\n",
    "### Using Torchtest to processs text data\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "import torchtext\n",
    "\n",
    "from torchtext.legacy.data import Field, BucketIterator, TabularDataset, LabelField\n",
    "\n",
    "import nltk \n",
    "nltk.download('punkt') # for punkt tokenizer\n",
    "\n",
    "from nltk import word_tokenize \n",
    "\n",
    "# torchtext field parameter specifies how data should be processed, here tokenized\n",
    "TEXT = Field(tokenize = word_tokenize)\n",
    "\n",
    "LABEL = LabelField(dtype = torch.float) # convert \n",
    "\n",
    "datafields = [ ('review_text', TEXT), ('label', LABEL)] \n",
    "\n",
    "# specify what data that will work with, split to train and text, map to field \n",
    "trn, tst = TabularDataset.splits(path = '/Users/andreamock/Documents/review_datasets',\n",
    "                               train = 'all_en_train.csv', test = 'all_en_test.csv', format = 'csv',\n",
    "                               skip_header = True, fields = datafields)\n",
    "\n",
    "\n",
    "# training examples \n",
    "trn[:5]\n",
    "\n",
    "print(f'Number of training examples: {len(trn)}')\n",
    "print(f'Number of testing examples: {len(tst)}')\n",
    "\n",
    "# each example has label and text\n",
    "trn[5].__dict__.keys()\n",
    "\n",
    "trn[1].review_text # text has been tokenized in individual words\n",
    "\n",
    "trn[1].label\n",
    "\n",
    "# limit size of feature vectors to 15000, use one-encoding to get the top 15000 words in vocab\n",
    "TEXT.build_vocab(trn, max_size = 15000)\n",
    "\n",
    "LABEL.build_vocab(trn)\n",
    "\n",
    "print(f'Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}')\n",
    "print(f'Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}')\n",
    "# two additional tokens were added to vocab, one for unknown words and another for padding to make sentences equal lengths\n",
    "\n",
    "print(TEXT.vocab.freqs.most_common(50)) \n",
    "\n",
    "print(TEXT.vocab.itos[:10]) # integer to string mapping 0 and 1 to unknown and padding\n",
    "\n",
    "batch_size = 64 \n",
    "\n",
    "# returns a batch of examples where each example is of similar length (thus minimizing padding for each example)\n",
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (trn,tst), batch_size = batch_size, sort_key = lambda x: len(x.review_text), sort_within_batch = False\n",
    ")\n",
    "\n",
    "## Designing an RNN for binary text classification \n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        # input_dim = input dimensions of words \n",
    "        # embedding_dim = dimension of word embeddings, dense word representation for training RNN\n",
    "        # hidden_dim = dimension of hidden state of RNN\n",
    "        # output_dim = output dimensions of RNN output\n",
    "        \n",
    "        super().__init__()\n",
    "        #  convert one-hot encoded sentences to dense format using embeddings to represent each word\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        # input to rnn is current word's embedding and previous hidden state, one word per time instance (memory cell)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # fully connected layer to classify as positive or negative \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # input sentence (list of indexes of one hot encoded words) is represented using its embedding\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        embedded_dropout = self.dropout(embedded)\n",
    "        \n",
    "        # output = concatentation of hidden state for every time step (ie word) [sentence length, batch size, hiddendim]\n",
    "        # hidden = final hidden state fed into linear layer\n",
    "        output, (hidden, _) = self.rnn(embedded_dropout)\n",
    "        \n",
    "        hidden_1D = hidden.squeeze(0) # get rid of unnecessary dimension \n",
    "        \n",
    "        assert torch.equal(output[-1, :, :], hidden_1D) # confirm that it is indeed last hidden state \n",
    "        \n",
    "        return self.fc(hidden_1D) # last hidden state fed into fully connected layer\n",
    "\n",
    "# setting dimensions \n",
    "input_dim = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim=1\n",
    "\n",
    "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "model # see what our model looks like\n",
    "\n",
    "# train with optimizer\n",
    "import torch.optim as optim \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "# binary cross entropy with logits (cross-entropy for binary classification, \n",
    "# w/ sigmoid activation func to predict in range of 0 and 1)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "def train(model, iterator, optimizer, criterion): # helper function for training process\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:  # iterator over all batches of training data\n",
    "        \n",
    "        optimizer.zero_grad() # zero out gradients of optimizer\n",
    "                \n",
    "        predictions = model(batch.review_text).squeeze(1) # make predictions, squeeze to be 1d instead of [, ]\n",
    "        \n",
    "        loss = criterion(predictions, batch.label) # calculate loss\n",
    "        \n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.label).float() # how many were correct\n",
    "        \n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward() # backward pass on rnn\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() # keep track of epoch loss and accuracy\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    print(f' Epoch: {epoch+1}, Train loss: {train_loss}, Train Acc: {train_acc*100:.2f}%')\n",
    "\n",
    "Now we can test the accuracy on our test data.\n",
    "\n",
    "# don't want to update the parameters when evaluating the accuracy\n",
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in test_iterator:\n",
    "\n",
    "        predictions = model(batch.review_text).squeeze(1)\n",
    "\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        \n",
    "        correct = (rounded_preds == batch.label).float() \n",
    "        acc = correct.sum() / len(correct)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "test_loss = epoch_loss / len(test_iterator)\n",
    "test_acc  = epoch_acc / len(test_iterator)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
