{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BMkqoS2Nx3Gt"
   },
   "source": [
    "# Scraping Google Reviews\n",
    "The following notebook details how Google Maps reviews of parks in Montréal are being collected.\n",
    "\n",
    "It is broken down into the following sections: \n",
    "<br>1. [Loading necessary libraries](#loading-lib)\n",
    "<br>2. [Collecting park information](#collecting-park-info)\n",
    "<br>3. [Collecting Google Maps data](#google-maps-calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"loading-lib\"></a>\n",
    "## 1. Loading necessary libraries\n",
    "One of the essential libraries for scraping web data is Selenium. To use Selenium, it first has to be installed as well as making sure that certain options are set for later scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kXbnv6BK4TXW",
    "outputId": "90af40f6-1d17-47ad-d69a-a335fbb41c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
      "\r",
      "\u001b[K     |▍                               | 10kB 16.4MB/s eta 0:00:01\r",
      "\u001b[K     |▊                               | 20kB 22.7MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 30kB 26.5MB/s eta 0:00:01\r",
      "\u001b[K     |█▌                              | 40kB 28.6MB/s eta 0:00:01\r",
      "\u001b[K     |█▉                              | 51kB 31.5MB/s eta 0:00:01\r",
      "\u001b[K     |██▏                             | 61kB 26.1MB/s eta 0:00:01\r",
      "\u001b[K     |██▌                             | 71kB 25.4MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 81kB 26.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 92kB 27.7MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 102kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 112kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████▍                           | 122kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████▊                           | 133kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 143kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▍                          | 153kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████▉                          | 163kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████▏                         | 174kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 184kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████▉                         | 194kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 204kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 215kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 225kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 235kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████▊                       | 245kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 256kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▍                      | 266kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▉                      | 276kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 286kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▌                     | 296kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▉                     | 307kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 317kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 327kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 337kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 348kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▊                   | 358kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 368kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▍                  | 378kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▊                  | 389kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▏                 | 399kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▌                 | 409kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▉                 | 419kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▏                | 430kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 440kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 450kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 460kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 471kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 481kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▍              | 491kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▊              | 501kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▏             | 512kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 522kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▉             | 532kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▏            | 542kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 552kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 563kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 573kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 583kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 593kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▍          | 604kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▊          | 614kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 624kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▌         | 634kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▉         | 645kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▏        | 655kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▌        | 665kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 675kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 686kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 696kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████       | 706kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▍      | 716kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▊      | 727kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████      | 737kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▍     | 747kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 757kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 768kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 778kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████    | 788kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▎   | 798kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▋   | 808kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 819kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▍  | 829kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▊  | 839kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████  | 849kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▍ | 860kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 870kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 880kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 890kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 901kB 29.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 911kB 29.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from selenium) (1.24.3)\n",
      "Installing collected packages: selenium\n",
      "Successfully installed selenium-3.141.0\n",
      "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
      "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n",
      "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Hit:11 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "Get:12 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
      "Get:13 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,185 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,415 kB]\n",
      "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Ign:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n",
      "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [599 kB]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,185 kB]\n",
      "Get:20 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [40.9 kB]\n",
      "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,619 kB]\n",
      "Fetched 9,312 kB in 3s (3,357 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
      "Suggested packages:\n",
      "  webaccounts-chromium-extension unity-chromium-extension\n",
      "The following NEW packages will be installed:\n",
      "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
      "  chromium-codecs-ffmpeg-extra\n",
      "0 upgraded, 4 newly installed, 0 to remove and 47 not upgraded.\n",
      "Need to get 86.0 MB of archives.\n",
      "After this operation, 298 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 91.0.4472.101-0ubuntu0.18.04.1 [1,124 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 91.0.4472.101-0ubuntu0.18.04.1 [76.1 MB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 91.0.4472.101-0ubuntu0.18.04.1 [3,937 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 91.0.4472.101-0ubuntu0.18.04.1 [4,837 kB]\n",
      "Fetched 86.0 MB in 3s (28.6 MB/s)\n",
      "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
      "(Reading database ... 160772 files and directories currently installed.)\n",
      "Preparing to unpack .../chromium-codecs-ffmpeg-extra_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package chromium-browser.\n",
      "Preparing to unpack .../chromium-browser_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package chromium-browser-l10n.\n",
      "Preparing to unpack .../chromium-browser-l10n_91.0.4472.101-0ubuntu0.18.04.1_all.deb ...\n",
      "Unpacking chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
      "Selecting previously unselected package chromium-chromedriver.\n",
      "Preparing to unpack .../chromium-chromedriver_91.0.4472.101-0ubuntu0.18.04.1_amd64.deb ...\n",
      "Unpacking chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
      "Setting up chromium-codecs-ffmpeg-extra (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
      "Setting up chromium-browser (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
      "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
      "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
      "Setting up chromium-chromedriver (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
      "Setting up chromium-browser-l10n (91.0.4472.101-0ubuntu0.18.04.1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
      "Processing triggers for mime-support (3.60ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
     ]
    }
   ],
   "source": [
    "# install necessary libraries \n",
    "!pip install selenium\n",
    "!apt-get update # to update ubuntu to correctly run apt install\n",
    "!apt install chromium-chromedriver\n",
    "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7-LCp1r04cRO"
   },
   "outputs": [],
   "source": [
    "# making sure that we are in the correct path \n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "WdLIfAtcxxwc"
   },
   "outputs": [],
   "source": [
    "# load selenium module for scraping \n",
    "from selenium import webdriver \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "from selenium.common.exceptions import TimeoutException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "NNLzlTAU2URQ"
   },
   "outputs": [],
   "source": [
    "# update options for scraping \n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "id": "iy--IROz3g67"
   },
   "outputs": [],
   "source": [
    "# create a webdriver browser instance to make website calls\n",
    "#browser = webdriver.Chrome('chromedriver', options=chrome_options)\n",
    "\n",
    "# if developing locally and not in Google Collab\n",
    "browser = webdriver.Chrome(executable_path=\"/Users/andreamock/Documents/chromedriver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f31tGVzhySRb"
   },
   "source": [
    "<a id=\"collecting-park-info\"></a>\n",
    "## 2. Collecting park information \n",
    "\n",
    "### 2.1 Collecting names of parks \n",
    "There are multiple parks in Montréal. There are multiple approaches that can be taken in order to get a complete list of parks. The official website of Montréal contains a [list of parks](https://montreal.ca/lieux?mtl_content.lieux.category.code=PARC) in the city which will be used as the basis for collecting reviews for different parks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jqvNv7O4_0L"
   },
   "outputs": [],
   "source": [
    "# get the website with all the parks in Montréal\n",
    "browser.get('https://montreal.ca/lieux?mtl_content.lieux.installation.code=PARC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3s7Q8ugn4_77"
   },
   "outputs": [],
   "source": [
    "def gatherParkNames(browserEl):\n",
    "    ''' Searches for the park names as well as urls to their corresponding site.\n",
    "    Returns a list of tuples, where each tuple contains the park name and corresponding url'''\n",
    "\n",
    "    # find_elements_by_xpath returns an array of selenium objects.\n",
    "    park_elements = browserEl.find_elements_by_xpath('//div[@class=\"list-group list-group-teaser hub-list-group \"]/a')\n",
    "\n",
    "    # extract the links and names of the parks \n",
    "    all_park_info = []\n",
    "    for p in park_elements: \n",
    "        park_name= p.text.split('\\n')[0] # just extract park name, not part of city and address\n",
    "        park_url = p.get_attribute('href')\n",
    "        all_park_info.append((park_name, park_url))\n",
    "\n",
    "    return all_park_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FEf22KWY5AF8"
   },
   "outputs": [],
   "source": [
    "def getAllParks(browserEl, numPages): \n",
    "    '''given the number of pages to traverse extracts all of the parks on the Montréal website and \n",
    "    returns the park name, the url to an information page for that park in the form of a list'''\n",
    "    \n",
    "    allparksInfo = [] # list to collect the information about all parks\n",
    "    for i in range(numPages): \n",
    "        browserEl.get('https://montreal.ca/lieux?mtl_content.lieux.installation.code=PARC&page='+str(i+1))\n",
    "        parksInfo = gatherParkNames(browserEl) # gather park information from one of the park overview pages\n",
    "        allparksInfo = allparksInfo + parksInfo\n",
    "\n",
    "    return allparksInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "DVHdbnB6ChbI"
   },
   "outputs": [],
   "source": [
    "# gather all of the park names from the Montréal website\n",
    "allParks = getAllParks(browser, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bjja853ECzcm",
    "outputId": "9cf0cc81-4aa8-42f0-82d4-3c0342309291"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "948"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of total parks \n",
    "len(allParks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IfObm-6UC461",
    "outputId": "6b6e5fc7-5e86-4e34-e18b-7c2552504e5d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Aire de repos 8e Avenue',\n",
       " 'https://montreal.ca/lieux/aire-de-repos-8e-avenue')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample entry of a park\n",
    "allParks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Extracting additional park information \n",
    "The Montréal park overview site also has a designated page for each park which offers information about each park opening times, general information as well as a link to Google maps for the park. Therefore since we collected the name of each park as well as to the individual site designated to each park we use it as a way to gather additional information about the park for later if needed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "odRrhzj5D8bM"
   },
   "outputs": [],
   "source": [
    "def extractAdditionalParkInfo(parkInfo, browserEl):\n",
    "    ''' Given a list of park names and corresponding urls, extracts the park's google maps url as well as description\n",
    "    if present. Returns a list of tuples that contains the park name, the link to the park's site on the montreal  \n",
    "    website and the description of the park \n",
    "    '''\n",
    "    fullParkInfo = []\n",
    "    for parkName, parkLink in parkInfo:\n",
    "        browserEl.get(parkLink)\n",
    "        try: \n",
    "            parkUrl = browserEl.find_elements_by_xpath(\n",
    "                '//div[@class=\"list-item-content\"]/div[@class=\"list-item-action mt-1\"]/a')\n",
    "            googleMapsUrl = parkUrl[0].get_attribute('href') #retrieve the url to Google Maps\n",
    "        except: \n",
    "            googleMapsUrl = None\n",
    "        \n",
    "        # try extracting a description, if not present just set to None\n",
    "        try: \n",
    "            # get a description of location\n",
    "            description = browser.find_elements_by_xpath('//div[@class=\"content-module-stacked\"]/div/p')[0].text\n",
    "        \n",
    "        except: \n",
    "            description = None\n",
    "        \n",
    "        fullParkInfo.append((parkName, parkLink, googleMapsUrl, description))\n",
    "    return fullParkInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TusRFAFtD8jc",
    "outputId": "8dbf97aa-3687-4969-8c96-1766f1c58e49"
   },
   "outputs": [],
   "source": [
    "# extract additional park info\n",
    "allParksData = extractAdditionalParkInfo(allParks, browser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oBcrvgnCD8oi",
    "outputId": "82a8b2cb-11cb-42fd-87e1-3e79ea2ab0ea"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aire de repos 8e Avenue',\n",
       "  'https://montreal.ca/lieux/aire-de-repos-8e-avenue',\n",
       "  'https://www.google.com/maps/search/?api=1&query=Boulevard%20Saint-Joseph%20Lachine%20H8S%202M2%20Qu%C3%A9bec,%20Canada',\n",
       "  'L’aire de repos de la 8e Avenue offre un point de vue sur le canal de Lachine.')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample collected data entry \n",
    "allParksData[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having collected data for all the parks in Montréal, before moving on to Google Maps it is important to saveguard the data. To do so, the collected data set will be saved in a CVS file and can be easily loaded in the next time without having to repeat the data collecting step again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "8f063cdUD8uJ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>link</th>\n",
       "      <th>google_maps</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aire de repos 8e Avenue</td>\n",
       "      <td>https://montreal.ca/lieux/aire-de-repos-8e-avenue</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>L’aire de repos de la 8e Avenue offre un point...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bassin de la Brunante</td>\n",
       "      <td>https://montreal.ca/lieux/bassin-de-la-brunante</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>Le bassin de la Brunante est un lieu privilégi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Belvédère du Chemin-Qui-Marche</td>\n",
       "      <td>https://montreal.ca/lieux/belvedere-du-chemin-...</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>C’est un parc linéaire proche du fleuve Saint-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boisé du parc Marcel-Laurin</td>\n",
       "      <td>https://montreal.ca/lieux/boise-du-parc-marcel...</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>Consultez la carte des sentiers.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Boisé Saint-Conrad</td>\n",
       "      <td>https://montreal.ca/lieux/boise-saint-conrad</td>\n",
       "      <td>https://www.google.com/maps/search/?api=1&amp;quer...</td>\n",
       "      <td>Venez profiter des attraits de la nature ou pr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             name  \\\n",
       "0         Aire de repos 8e Avenue   \n",
       "1           Bassin de la Brunante   \n",
       "2  Belvédère du Chemin-Qui-Marche   \n",
       "3     Boisé du parc Marcel-Laurin   \n",
       "4              Boisé Saint-Conrad   \n",
       "\n",
       "                                                link  \\\n",
       "0  https://montreal.ca/lieux/aire-de-repos-8e-avenue   \n",
       "1    https://montreal.ca/lieux/bassin-de-la-brunante   \n",
       "2  https://montreal.ca/lieux/belvedere-du-chemin-...   \n",
       "3  https://montreal.ca/lieux/boise-du-parc-marcel...   \n",
       "4       https://montreal.ca/lieux/boise-saint-conrad   \n",
       "\n",
       "                                         google_maps  \\\n",
       "0  https://www.google.com/maps/search/?api=1&quer...   \n",
       "1  https://www.google.com/maps/search/?api=1&quer...   \n",
       "2  https://www.google.com/maps/search/?api=1&quer...   \n",
       "3  https://www.google.com/maps/search/?api=1&quer...   \n",
       "4  https://www.google.com/maps/search/?api=1&quer...   \n",
       "\n",
       "                                         description  \n",
       "0  L’aire de repos de la 8e Avenue offre un point...  \n",
       "1  Le bassin de la Brunante est un lieu privilégi...  \n",
       "2  C’est un parc linéaire proche du fleuve Saint-...  \n",
       "3                   Consultez la carte des sentiers.  \n",
       "4  Venez profiter des attraits de la nature ou pr...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save park information in dataframe\n",
    "park_df = pd.DataFrame(allParksData, columns=['name', 'link', 'google_maps', 'description'])\n",
    "park_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data in csv file\n",
    "#park_df.to_csv('ParkInformation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJfkNCZvJyFC"
   },
   "source": [
    "<a id=\"google-maps-calls\"></a>\n",
    "## 3. Making Google API calls\n",
    "After having collected the name of all the parks in Montréal, the next step is to search them up on Google Maps and extract the reviews for each park. \n",
    "\n",
    "### 3.1 Functions to collect reviews\n",
    "For the collection of reviews Selenium will be utilized. In order to search for a particular park, one must first search up the name of the park, click on the reviews, scroll down to gather all reviews since the site is dynamically loaded and finally collect the reviews and store them. For each park the reviews will be stored in a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "FZuhDcTJotiM"
   },
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ryjsGayAD8zU"
   },
   "outputs": [],
   "source": [
    "def searchplace(browserEl, search):\n",
    "    ''' finds the search bar and performes a search for a given search phrase'''\n",
    "    place = browserEl.find_element_by_class_name(\"tactile-searchbox-input\")\n",
    "    place.clear()\n",
    "    place.send_keys(search)\n",
    "    submitButton = browserEl.find_element_by_xpath(\"/html/body/jsl/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/div[1]/button\")\n",
    "    submitButton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def goToAllReviews(browserEl):\n",
    "    '''helper function that clicks on more reviews once a google maps place is loaded'''\n",
    "    element = browserEl.find_elements_by_xpath('//button[@jsaction=\\'pane.reviewlist.goToReviews\\']')\n",
    "    time.sleep(2)\n",
    "    element[0].click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wZ21Ows0oyXq",
    "outputId": "7142927e-e59d-473f-9e03-3cbdf5fa5fc1"
   },
   "outputs": [],
   "source": [
    "def scroll(browserEl): \n",
    "    '''scrolls down to dynamically load all of the reviews'''\n",
    "    \n",
    "    keepScrolling = True\n",
    "\n",
    "    while keepScrolling: \n",
    "        time.sleep(2) # to allow for everything to load\n",
    "        try: \n",
    "            # scroll down \n",
    "            scrollable_div = browserEl.find_element_by_css_selector('div.wo1ice-loading.noprint')\n",
    "            browserEl.execute_script(\"arguments[0].scrollIntoView(true);\", scrollable_div)\n",
    "        except: \n",
    "            # once scrolled to the bottem print notification\n",
    "            print('reached the end')\n",
    "            keepScrolling = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expandReview(browserEl):\n",
    "    '''Helper function that clicks open all reviews that are longer and for which the text is otherwise not \n",
    "    fully visible'''\n",
    "    \n",
    "    expandReviews = browserEl.find_elements_by_xpath('//button[@jsaction=\\'pane.review.expandReview\\']')\n",
    "\n",
    "    for ex in expandReviews: \n",
    "        time.sleep(2)\n",
    "        try: \n",
    "            ex.click()\n",
    "        except:\n",
    "            print('error expanding review pane')\n",
    "    #print('All reviews expanded successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectReviewInfo(review,reviewFor): \n",
    "    ''' \n",
    "    Given the html for a review, as well as the name of the park for which the review is (reviewFor) extracts the \n",
    "    review id, username, url of the contributer profile, published date, number of previous reviews user has, \n",
    "    number of stars and the text of the review\n",
    "    if there and returns a dictionary with the review information \n",
    "    '''\n",
    "    \n",
    "    reviewInfo = {} # dictionary to store review information \n",
    "    \n",
    "    review_id = review['data-review-id']\n",
    "    username = review.find('div', class_='ODSEW-ShBeI-title').find('span').text\n",
    "    user_url = review.find('a')['href']\n",
    "    date_published = review.find('span', class_='ODSEW-ShBeI-RgZmSc-date').text\n",
    "    num_stars = float(review.find('span', class_='ODSEW-ShBeI-H1e3jb')['aria-label'].split(' ')[1])\n",
    "    \n",
    "    try: # collect number of previous reviews by user if present\n",
    "        review_nums = review.find('div', class_='ODSEW-ShBeI-VdSJob').find_all('span')[1].text\n",
    "        num_reviews = int(re.findall('\\d+', review_nums.split()[0])[0]) \n",
    "    except:\n",
    "        num_reviews = 0\n",
    "    \n",
    "    try: # extract review text if present\n",
    "        review_text = review.find('span', class_='ODSEW-ShBeI-text').text\n",
    "    except Exception as e:\n",
    "        review_text = None\n",
    "    \n",
    "    reviewInfo['review_for'] = reviewFor\n",
    "    reviewInfo['review_id'] = review_id\n",
    "    reviewInfo['username'] = username\n",
    "    reviewInfo['user_url'] = user_url\n",
    "    reviewInfo['published'] = date_published\n",
    "    reviewInfo['date_retrieved'] = datetime.now()\n",
    "    reviewInfo['num_stars'] = num_stars\n",
    "    reviewInfo['num_reviews'] = num_reviews\n",
    "    reviewInfo['review_text'] = review_text\n",
    "    \n",
    "    return reviewInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "id": "iAYwMT4montu"
   },
   "outputs": [],
   "source": [
    "def collectParkReviews(query, browserEl):\n",
    "    '''Given the name of a park does a google maps search for the park, expands all reviews and scrapes them.\n",
    "    If no park reviews are found None is returned, otherwise all of the reviews are returned in the form of a list'''\n",
    "    \n",
    "    time.sleep(2)\n",
    "    searchplace(browserEl, query + ' Montréal') # searches for the park in search bar\n",
    "    \n",
    "    try: \n",
    "        time.sleep(5) # leave time to load page\n",
    "        goToAllReviews(browserEl) # tries going to the review page\n",
    "        time.sleep(2) \n",
    "        \n",
    "        scroll(browserEl) # scrolls down\n",
    "        time.sleep(2) # leave time to load page\n",
    "        \n",
    "        expandReview(browserEl) # expands long reviews\n",
    "        time.sleep(3) # leave time to load page\n",
    "        \n",
    "        # use BeautifulSoup to parse and extract the information for each review \n",
    "        response = BeautifulSoup(browserEl.page_source, 'html.parser')\n",
    "        rblock = response.find_all('div', class_='ODSEW-ShBeI NIyLF-haAclf gm2-body-2')\n",
    "        allReviewData = [collectReviewInfo(ireview, query) for ireview in rblock]\n",
    "        return allReviewData # return the list of collected review information \n",
    "    except:\n",
    "        print('unable to collect reviews')\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collectMultipleReviews(parkList, browserEl):\n",
    "    '''Given a list of multiple park names searches for reviews for all of the parks and for each successful \n",
    "    collection of a parks saves the reviews for that particular park in a csv file with the parks name. \n",
    "    If a park did not have any reviews or review collection was unsuccessful the names of these parks will be returned \n",
    "    as a list for further troubleshooting. \n",
    "    '''\n",
    "    \n",
    "    unsuccessful = []\n",
    "    for park in parkList: \n",
    "        browserEl.get('https://www.google.com/maps')\n",
    "        time.sleep(5)\n",
    "        reviewsData = collectParkReviews(park, browserEl)\n",
    "        if reviewsData is None: \n",
    "            unsuccessful.append(park)\n",
    "        else:\n",
    "            df = pd.DataFrame(reviewsData)\n",
    "            df.to_csv(park + '.csv')\n",
    "            \n",
    "    return unsuccessful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "UvoVsZ4RqrT2"
   },
   "outputs": [],
   "source": [
    "browser.get('https://www.google.com/maps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Parc Moulin-du-Rapide',\n",
       " 'Parc Mozart',\n",
       " 'Parc Mullins-Richmond',\n",
       " 'Parc Mullins-Wellington',\n",
       " 'Parc Munro',\n",
       " 'Parc Murielle-Dumont',\n",
       " 'Parc Napoléon',\n",
       " 'Parc Napoléon-Sénécal',\n",
       " 'Parc-nature de l’Anse-à-l’Orme',\n",
       " \"Parc-nature de l'Île-de-la-Visitation\",\n",
       " 'Parc-nature de la Pointe-aux-Prairies',\n",
       " \"Parc-nature du Bois-de-L'Île-Bizard\",\n",
       " 'Parc-nature du Bois-de-Liesse',\n",
       " 'Parc-nature du Bois-de-Saraguay',\n",
       " 'Parc-nature du Cap-Saint-Jacques',\n",
       " 'Parc-nature du Ruisseau-De Montigny',\n",
       " 'Parc Nelson-Mandela',\n",
       " 'Parc Nesbitt',\n",
       " 'Parc Neuville-sur-Vanne',\n",
       " 'Parc Nicolas-Tillemont']"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of some of the parks \n",
    "list(park_df['name'][640:660])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el found []\n",
      "unable to collect reviews\n",
      "el found [<selenium.webdriver.remote.webelement.WebElement (session=\"73c99ef7c0f0c61fc16a1fa91f433885\", element=\"94275dbd-8f89-4e0c-9a3b-b35e583a8726\")>]\n",
      "reached the end\n",
      "All reviews expanded successfully\n",
      "el found [<selenium.webdriver.remote.webelement.WebElement (session=\"73c99ef7c0f0c61fc16a1fa91f433885\", element=\"d5f4eace-e4f4-486e-8a8e-d81da95d706f\")>]\n",
      "reached the end\n",
      "All reviews expanded successfully\n",
      "el found [<selenium.webdriver.remote.webelement.WebElement (session=\"73c99ef7c0f0c61fc16a1fa91f433885\", element=\"86163cc6-7cd5-468c-8f9a-eee6f72f1cde\")>]\n"
     ]
    }
   ],
   "source": [
    "# scraping of a group of parks \n",
    "missing11 = collectMultipleReviews(list(park_df['name'][770:800]), browser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Collecting reviews with special format\n",
    "After searching for certain parks there are mutliple parks with a particular name or only 1 review for that park. Therefore, it is necessary to add an additional processing step for the parks for which not data was abke to be collected via the code from above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldParks = [ 'Parc Guillaume-Couture', 'Parc Gédéon-De Catalogne', \n",
    " 'Parc-école Saint-Pierre-Apôtre', 'Parc du Pied-du-Courant', \n",
    " 'Parc du Père-Marquette', 'Parc du Mail', 'Parc du Bocage', 'Parc des Hirondelles', 'Parc des Écluses', 'Parc de la Fontaine',\n",
    " 'Mini-parc Querbes', 'Parc Coubertin', 'Parc Chamberland', 'Parc Chabot', 'Parc Bélanger De Chateaubriand',\n",
    "'Parc Baldwin', 'Parc Houde', 'Parc Angrignon', 'Parc Ahuntsic', 'Parc J.-Albert-Gariépy', 'Parc J.O.R.-Leduc',\n",
    " 'Parc Jarry','Parc Gédéon-De Catalogne', 'Parc Jeanne-Mance','Parc Jessie-Maxwell-Smith','Parc Lucie-Bruneau',\n",
    "  'Parc Mackenzie-King','Parc Maisonneuve','Parc Mignault', 'Parc Monty', 'Parc-nature de la Pointe-aux-Prairies',       \n",
    "'Parc-nature du Bois-de-Liesse', 'Parc-nature du Cap-Saint-Jacques', 'Parc Nicolas-Viel', 'Parc Ovila-Pelletier',\n",
    "         'Parc Painter','Parc Paul-Séguin', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Scraping Google Reviews.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
