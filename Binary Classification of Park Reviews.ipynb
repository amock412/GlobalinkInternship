{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification of Park Reviews\n",
    "By scraping Google Maps to gather reviews of parks in Montréal a dataset of 45k+ reviews was collected. The next step after data collection is to create a classifier that determines if a review is expressing positiv or negative sentiment about the park. To come up with a classifier various models are tested and compared. \n",
    "\n",
    "The following notebook is broken down into the following sections: \n",
    "<br>**1. [Data Exploration](#data-exp)\n",
    "<br>&nbsp;&nbsp; 1.1 [Read in data](#read-data)\n",
    "<br>&nbsp;&nbsp; 1.2 [Calculating summary statistics](#sum-stats)\n",
    "<br>&nbsp;&nbsp; 1.3 [Gathering most common terms](#common-terms)\n",
    "<br>2. [Testing different classifiers](#classifiers)\n",
    "<br>&nbsp;&nbsp; 2.1 [Text preprocessing](#pre-process)\n",
    "<br>&nbsp;&nbsp; 2.2 [Testing classifiers](#test-class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data-exp\"></a> \n",
    "## 1. Data Exploration \n",
    "The first step before jumping into creating classifiers, is to get familiar with the datasets. The first section is broken down into first loading in the data, looking at the distribution of stars for the reviews and also looking for patterns in reviews to see if any terms pop up more in negative or positive reviews. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"read-data\"></a> \n",
    "### 1.1 Read in data\n",
    "The data is saved in two datasets, both saved in csv files. The first one includes all of the reviews in English (allEnReviews.csv) and the second dataset includes all reviews in different languages and includes a column that contains information about the language a review is in (ParkReviewsLang.csv). Using the second dataset the French reviews can be extracted and analyzed as one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_for</th>\n",
       "      <th>review_id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_url</th>\n",
       "      <th>published</th>\n",
       "      <th>date_retrieved</th>\n",
       "      <th>num_stars</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNpeGF6TTNnRRAB</td>\n",
       "      <td>Claudia</td>\n",
       "      <td>https://www.google.com/maps/contrib/1001449741...</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.211296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>One of the nicest entry points to this invitin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURDOGEyMGpnRRAB</td>\n",
       "      <td>Nate Neel</td>\n",
       "      <td>https://www.google.com/maps/contrib/1121030547...</td>\n",
       "      <td>8 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.212245</td>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Waterfront to fish or just relax, great place ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUM4Nk9Ya3lnRRAB</td>\n",
       "      <td>Yucel Salimoglu</td>\n",
       "      <td>https://www.google.com/maps/contrib/1034180738...</td>\n",
       "      <td>11 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.213178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Everything except the parking is good here.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNVdWNUbE9REAE</td>\n",
       "      <td>COCO BEADZ</td>\n",
       "      <td>https://www.google.com/maps/contrib/1036060504...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.214115</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>Defenely the best park in Montreal East, Tetre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUMwdHJDTm1nRRAB</td>\n",
       "      <td>Anna Maria Fiore</td>\n",
       "      <td>https://www.google.com/maps/contrib/1016779009...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.215069</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>It's so peaceful and happy place near the water</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         review_for                             review_id  \\\n",
       "0  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUNpeGF6TTNnRRAB   \n",
       "1  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSURDOGEyMGpnRRAB   \n",
       "2  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUM4Nk9Ya3lnRRAB   \n",
       "3  Parc de la Capture-d'Ethan-Allen   ChZDSUhNMG9nS0VJQ0FnSUNVdWNUbE9REAE   \n",
       "4  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUMwdHJDTm1nRRAB   \n",
       "\n",
       "           username                                           user_url  \\\n",
       "0           Claudia  https://www.google.com/maps/contrib/1001449741...   \n",
       "1         Nate Neel  https://www.google.com/maps/contrib/1121030547...   \n",
       "2   Yucel Salimoglu  https://www.google.com/maps/contrib/1034180738...   \n",
       "3        COCO BEADZ  https://www.google.com/maps/contrib/1036060504...   \n",
       "4  Anna Maria Fiore  https://www.google.com/maps/contrib/1016779009...   \n",
       "\n",
       "       published              date_retrieved  num_stars  num_reviews  \\\n",
       "0   7 months ago  2021-06-20 22:04:09.211296        4.0        107.0   \n",
       "1   8 months ago  2021-06-20 22:04:09.212245        5.0        121.0   \n",
       "2  11 months ago  2021-06-20 22:04:09.213178        4.0         79.0   \n",
       "3     a year ago  2021-06-20 22:04:09.214115        4.0        128.0   \n",
       "4     a year ago  2021-06-20 22:04:09.215069        5.0         39.0   \n",
       "\n",
       "                                         review_text  label  \n",
       "0  One of the nicest entry points to this invitin...      1  \n",
       "1  Waterfront to fish or just relax, great place ...      1  \n",
       "2        Everything except the parking is good here.      1  \n",
       "3  Defenely the best park in Montreal East, Tetre...      1  \n",
       "4    It's so peaceful and happy place near the water      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in english reviews \n",
    "parkReviews = pd.read_csv('allEnReviews.csv', index_col=0)\n",
    "parkReviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 3312 3 star reviews. When using the number of stars as a cutoff for wether something is classfied as positive or negative, it may be helpful to first get a sense of what type of reviews fall into the three star category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_for</th>\n",
       "      <th>review_id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_url</th>\n",
       "      <th>published</th>\n",
       "      <th>date_retrieved</th>\n",
       "      <th>num_stars</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "      <th>word_count</th>\n",
       "      <th>uppercase_char_count</th>\n",
       "      <th>special_char_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNnd0xqYmhnRRAB</td>\n",
       "      <td>Marc-André Maurice</td>\n",
       "      <td>https://www.google.com/maps/contrib/1054968570...</td>\n",
       "      <td>4 years ago</td>\n",
       "      <td>2021-06-20 22:04:09.223866</td>\n",
       "      <td>3.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>If you want to have a beer by the St-Laurence ...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURnd2R1bW5nRRAB</td>\n",
       "      <td>Carismé Pierre</td>\n",
       "      <td>https://www.google.com/maps/contrib/1056897378...</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>2021-06-20 22:04:09.225823</td>\n",
       "      <td>3.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>Correct...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNxMWM2bVFREAE</td>\n",
       "      <td>Steve Huard</td>\n",
       "      <td>https://www.google.com/maps/contrib/1165278777...</td>\n",
       "      <td>6 days ago</td>\n",
       "      <td>2021-06-20 22:04:09.228581</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Très beau mes j'aimerais pouvoir descendre au ...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Parc Mohawk</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNpbVB6SjJBRRAB</td>\n",
       "      <td>Miguel Veliz</td>\n",
       "      <td>https://www.google.com/maps/contrib/1101192075...</td>\n",
       "      <td>8 months ago</td>\n",
       "      <td>2021-06-22 11:54:53.183611</td>\n",
       "      <td>3.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>Field is uneven, represents risks for players....</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Parc Mohawk</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUM0bVBIazB3RRAB</td>\n",
       "      <td>Fonaq</td>\n",
       "      <td>https://www.google.com/maps/contrib/1076101585...</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>2021-06-22 11:54:53.191064</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>Great place to go play tennis, soccer or half ...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41749</th>\n",
       "      <td>Square Dézéry</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURDbU9lRnhnRRAB</td>\n",
       "      <td>Andre Gagnon</td>\n",
       "      <td>https://www.google.com/maps/contrib/1019125653...</td>\n",
       "      <td>9 months ago</td>\n",
       "      <td>2021-06-22 20:31:39.563398</td>\n",
       "      <td>3.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Too many itinerants next to Notre Dame campsite</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41758</th>\n",
       "      <td>Square Dézéry</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNRMW8tbXRBRRAB</td>\n",
       "      <td>Francis Tanguay</td>\n",
       "      <td>https://www.google.com/maps/contrib/1170721416...</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>2021-06-22 20:31:39.573976</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>A little too expensive for some article but ve...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41761</th>\n",
       "      <td>Square Dézéry</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURRMU1fM3pBRRAB</td>\n",
       "      <td>Johanne gauvreau</td>\n",
       "      <td>https://www.google.com/maps/contrib/1162172471...</td>\n",
       "      <td>3 years ago</td>\n",
       "      <td>2021-06-22 20:31:39.580552</td>\n",
       "      <td>3.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>Very good xx</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41783</th>\n",
       "      <td>Parc Paul-Séguin</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURnLS16Um93RRAB</td>\n",
       "      <td>Denise Le Blanc</td>\n",
       "      <td>https://www.google.com/maps/contrib/1040043322...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-23 16:12:02.475158</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>A small park ideal for young families, games, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41818</th>\n",
       "      <td>Parc Pierre-Boucher</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUM4Z2ZlUnR3RRAB</td>\n",
       "      <td>Martin Coursol</td>\n",
       "      <td>https://www.google.com/maps/contrib/1106775382...</td>\n",
       "      <td>11 months ago</td>\n",
       "      <td>2021-06-24 14:29:09.681038</td>\n",
       "      <td>3.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>Small park limited to a few benches. Perfect f...</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3312 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review_for                             review_id  \\\n",
       "13     Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUNnd0xqYmhnRRAB   \n",
       "15     Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSURnd2R1bW5nRRAB   \n",
       "18     Parc de la Capture-d'Ethan-Allen   ChZDSUhNMG9nS0VJQ0FnSUNxMWM2bVFREAE   \n",
       "121                         Parc Mohawk  ChdDSUhNMG9nS0VJQ0FnSUNpbVB6SjJBRRAB   \n",
       "124                         Parc Mohawk  ChdDSUhNMG9nS0VJQ0FnSUM0bVBIazB3RRAB   \n",
       "...                                 ...                                   ...   \n",
       "41749                     Square Dézéry  ChdDSUhNMG9nS0VJQ0FnSURDbU9lRnhnRRAB   \n",
       "41758                     Square Dézéry  ChdDSUhNMG9nS0VJQ0FnSUNRMW8tbXRBRRAB   \n",
       "41761                     Square Dézéry  ChdDSUhNMG9nS0VJQ0FnSURRMU1fM3pBRRAB   \n",
       "41783                  Parc Paul-Séguin  ChdDSUhNMG9nS0VJQ0FnSURnLS16Um93RRAB   \n",
       "41818               Parc Pierre-Boucher  ChdDSUhNMG9nS0VJQ0FnSUM4Z2ZlUnR3RRAB   \n",
       "\n",
       "                 username                                           user_url  \\\n",
       "13     Marc-André Maurice  https://www.google.com/maps/contrib/1054968570...   \n",
       "15         Carismé Pierre  https://www.google.com/maps/contrib/1056897378...   \n",
       "18            Steve Huard  https://www.google.com/maps/contrib/1165278777...   \n",
       "121          Miguel Veliz  https://www.google.com/maps/contrib/1101192075...   \n",
       "124                 Fonaq  https://www.google.com/maps/contrib/1076101585...   \n",
       "...                   ...                                                ...   \n",
       "41749        Andre Gagnon  https://www.google.com/maps/contrib/1019125653...   \n",
       "41758     Francis Tanguay  https://www.google.com/maps/contrib/1170721416...   \n",
       "41761    Johanne gauvreau  https://www.google.com/maps/contrib/1162172471...   \n",
       "41783     Denise Le Blanc  https://www.google.com/maps/contrib/1040043322...   \n",
       "41818      Martin Coursol  https://www.google.com/maps/contrib/1106775382...   \n",
       "\n",
       "           published              date_retrieved  num_stars  num_reviews  \\\n",
       "13       4 years ago  2021-06-20 22:04:09.223866        3.0         32.0   \n",
       "15       3 years ago  2021-06-20 22:04:09.225823        3.0         97.0   \n",
       "18        6 days ago  2021-06-20 22:04:09.228581        3.0          3.0   \n",
       "121     8 months ago  2021-06-22 11:54:53.183611        3.0         61.0   \n",
       "124      2 years ago  2021-06-22 11:54:53.191064        3.0         17.0   \n",
       "...              ...                         ...        ...          ...   \n",
       "41749   9 months ago  2021-06-22 20:31:39.563398        3.0         72.0   \n",
       "41758    3 years ago  2021-06-22 20:31:39.573976        3.0         18.0   \n",
       "41761    3 years ago  2021-06-22 20:31:39.580552        3.0        139.0   \n",
       "41783     a year ago  2021-06-23 16:12:02.475158        3.0         12.0   \n",
       "41818  11 months ago  2021-06-24 14:29:09.681038        3.0        116.0   \n",
       "\n",
       "                                             review_text  label  word_count  \\\n",
       "13     If you want to have a beer by the St-Laurence ...      0          12   \n",
       "15                                            Correct...      0           1   \n",
       "18     Très beau mes j'aimerais pouvoir descendre au ...      0          21   \n",
       "121    Field is uneven, represents risks for players....      0          20   \n",
       "124    Great place to go play tennis, soccer or half ...      0          11   \n",
       "...                                                  ...    ...         ...   \n",
       "41749    Too many itinerants next to Notre Dame campsite      0           8   \n",
       "41758  A little too expensive for some article but ve...      0          11   \n",
       "41761                                       Very good xx      0           3   \n",
       "41783  A small park ideal for young families, games, ...      0          13   \n",
       "41818  Small park limited to a few benches. Perfect f...      0          19   \n",
       "\n",
       "       uppercase_char_count  special_char_count  \n",
       "13                        3                   1  \n",
       "15                        1                   3  \n",
       "18                        1                   3  \n",
       "121                       4                   5  \n",
       "124                       1                   2  \n",
       "...                     ...                 ...  \n",
       "41749                     3                   0  \n",
       "41758                     1                   1  \n",
       "41761                     1                   0  \n",
       "41783                     2                   4  \n",
       "41818                     2                   3  \n",
       "\n",
       "[3312 rows x 13 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at 3 star reviews \n",
    "parkReviews[parkReviews['num_stars'] == 3.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41822, 11)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in park reviews with language labels\n",
    "parkReviews = pd.read_csv('ParkReviewsLang.csv', index_col=0)\n",
    "parkReviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_for</th>\n",
       "      <th>review_id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_url</th>\n",
       "      <th>published</th>\n",
       "      <th>date_retrieved</th>\n",
       "      <th>num_stars</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNpeGF6TTNnRRAB</td>\n",
       "      <td>Claudia</td>\n",
       "      <td>https://www.google.com/maps/contrib/1001449741...</td>\n",
       "      <td>7 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.211296</td>\n",
       "      <td>4.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>One of the nicest entry points to this invitin...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURDOGEyMGpnRRAB</td>\n",
       "      <td>Nate Neel</td>\n",
       "      <td>https://www.google.com/maps/contrib/1121030547...</td>\n",
       "      <td>8 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.212245</td>\n",
       "      <td>5.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>Waterfront to fish or just relax, great place ...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUM4Nk9Ya3lnRRAB</td>\n",
       "      <td>Yucel Salimoglu</td>\n",
       "      <td>https://www.google.com/maps/contrib/1034180738...</td>\n",
       "      <td>11 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.213178</td>\n",
       "      <td>4.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Everything except the parking is good here.</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNVdWNUbE9REAE</td>\n",
       "      <td>COCO BEADZ</td>\n",
       "      <td>https://www.google.com/maps/contrib/1036060504...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.214115</td>\n",
       "      <td>4.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>Defenely the best park in Montreal East, Tetre...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUMwdHJDTm1nRRAB</td>\n",
       "      <td>Anna Maria Fiore</td>\n",
       "      <td>https://www.google.com/maps/contrib/1016779009...</td>\n",
       "      <td>a year ago</td>\n",
       "      <td>2021-06-20 22:04:09.215069</td>\n",
       "      <td>5.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>It's so peaceful and happy place near the water</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         review_for                             review_id  \\\n",
       "0  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUNpeGF6TTNnRRAB   \n",
       "1  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSURDOGEyMGpnRRAB   \n",
       "2  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUM4Nk9Ya3lnRRAB   \n",
       "3  Parc de la Capture-d'Ethan-Allen   ChZDSUhNMG9nS0VJQ0FnSUNVdWNUbE9REAE   \n",
       "4  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUMwdHJDTm1nRRAB   \n",
       "\n",
       "           username                                           user_url  \\\n",
       "0           Claudia  https://www.google.com/maps/contrib/1001449741...   \n",
       "1         Nate Neel  https://www.google.com/maps/contrib/1121030547...   \n",
       "2   Yucel Salimoglu  https://www.google.com/maps/contrib/1034180738...   \n",
       "3        COCO BEADZ  https://www.google.com/maps/contrib/1036060504...   \n",
       "4  Anna Maria Fiore  https://www.google.com/maps/contrib/1016779009...   \n",
       "\n",
       "       published              date_retrieved  num_stars  num_reviews  \\\n",
       "0   7 months ago  2021-06-20 22:04:09.211296        4.0        107.0   \n",
       "1   8 months ago  2021-06-20 22:04:09.212245        5.0        121.0   \n",
       "2  11 months ago  2021-06-20 22:04:09.213178        4.0         79.0   \n",
       "3     a year ago  2021-06-20 22:04:09.214115        4.0        128.0   \n",
       "4     a year ago  2021-06-20 22:04:09.215069        5.0         39.0   \n",
       "\n",
       "                                         review_text  label lang  \n",
       "0  One of the nicest entry points to this invitin...      1   en  \n",
       "1  Waterfront to fish or just relax, great place ...      1   en  \n",
       "2        Everything except the parking is good here.      1   en  \n",
       "3  Defenely the best park in Montreal East, Tetre...      1   en  \n",
       "4    It's so peaceful and happy place near the water      1   en  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a look at some park reviews\n",
    "parkReviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17149, 11)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extrac french reviews only \n",
    "frenchReviews = parkReviews[parkReviews['lang'] == 'fr']\n",
    "frenchReviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the Google Maps reviews that are made in another language besides English also include an automatic English translation it is important to get rid of the English translation to obtain only the original French text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract French text and save in additional column \n",
    "frenchReviewsDf = frenchReviews.copy()\n",
    "frenchReviewText = frenchReviews['review_text'].apply(lambda x: x.split('(Original)')[-1].strip())\n",
    "frenchReviewsDf['french_text'] = frenchReviewText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_for</th>\n",
       "      <th>review_id</th>\n",
       "      <th>username</th>\n",
       "      <th>user_url</th>\n",
       "      <th>published</th>\n",
       "      <th>date_retrieved</th>\n",
       "      <th>num_stars</th>\n",
       "      <th>num_reviews</th>\n",
       "      <th>review_text</th>\n",
       "      <th>label</th>\n",
       "      <th>lang</th>\n",
       "      <th>french_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22684</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNxM3JIQjhBRRAB</td>\n",
       "      <td>Claude Gagnon</td>\n",
       "      <td>https://www.google.com/maps/contrib/1182846684...</td>\n",
       "      <td>a week ago</td>\n",
       "      <td>2021-06-20 22:04:09.230541</td>\n",
       "      <td>4.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>(Translated by Google) Very beautiful park to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>Tres beau parc pour faire un pinic et profiter...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22685</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSURLckpMTm5nRRAB</td>\n",
       "      <td>Guy Durand</td>\n",
       "      <td>https://www.google.com/maps/contrib/1056233036...</td>\n",
       "      <td>a month ago</td>\n",
       "      <td>2021-06-20 22:04:09.232736</td>\n",
       "      <td>5.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>(Translated by Google) The people are all very...</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>Les gens sont tous très sociables.\\nExceptionnel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22686</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNBNktMclNREAE</td>\n",
       "      <td>Dania Pascual</td>\n",
       "      <td>https://www.google.com/maps/contrib/1064940459...</td>\n",
       "      <td>2 years ago</td>\n",
       "      <td>2021-06-20 22:04:09.233660</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>(Translated by Google) Nice place to walk, jog...</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>Belle place pour marcher, jogger, promener le ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22687</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChdDSUhNMG9nS0VJQ0FnSUNxNWFEUzBBRRAB</td>\n",
       "      <td>Stéphane Lessard</td>\n",
       "      <td>https://www.google.com/maps/contrib/1061684432...</td>\n",
       "      <td>a week ago</td>\n",
       "      <td>2021-06-20 22:04:09.234580</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>(Translated by Google) Excellent food!\\n\\n(Ori...</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>Nourriture excellente !</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22688</th>\n",
       "      <td>Parc de la Capture-d'Ethan-Allen</td>\n",
       "      <td>ChZDSUhNMG9nS0VJQ0FnSUNLaTZ2YVFBEAE</td>\n",
       "      <td>Pitchou Kasongo</td>\n",
       "      <td>https://www.google.com/maps/contrib/1176531246...</td>\n",
       "      <td>2 months ago</td>\n",
       "      <td>2021-06-20 22:04:09.235577</td>\n",
       "      <td>4.0</td>\n",
       "      <td>93.0</td>\n",
       "      <td>(Translated by Google) I like to get some fres...</td>\n",
       "      <td>1</td>\n",
       "      <td>fr</td>\n",
       "      <td>J aime bien pour prendre de l air frais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review_for                             review_id  \\\n",
       "22684  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUNxM3JIQjhBRRAB   \n",
       "22685  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSURLckpMTm5nRRAB   \n",
       "22686  Parc de la Capture-d'Ethan-Allen   ChZDSUhNMG9nS0VJQ0FnSUNBNktMclNREAE   \n",
       "22687  Parc de la Capture-d'Ethan-Allen  ChdDSUhNMG9nS0VJQ0FnSUNxNWFEUzBBRRAB   \n",
       "22688  Parc de la Capture-d'Ethan-Allen   ChZDSUhNMG9nS0VJQ0FnSUNLaTZ2YVFBEAE   \n",
       "\n",
       "               username                                           user_url  \\\n",
       "22684     Claude Gagnon  https://www.google.com/maps/contrib/1182846684...   \n",
       "22685        Guy Durand  https://www.google.com/maps/contrib/1056233036...   \n",
       "22686     Dania Pascual  https://www.google.com/maps/contrib/1064940459...   \n",
       "22687  Stéphane Lessard  https://www.google.com/maps/contrib/1061684432...   \n",
       "22688   Pitchou Kasongo  https://www.google.com/maps/contrib/1176531246...   \n",
       "\n",
       "          published              date_retrieved  num_stars  num_reviews  \\\n",
       "22684    a week ago  2021-06-20 22:04:09.230541        4.0         86.0   \n",
       "22685   a month ago  2021-06-20 22:04:09.232736        5.0         53.0   \n",
       "22686   2 years ago  2021-06-20 22:04:09.233660        5.0         41.0   \n",
       "22687    a week ago  2021-06-20 22:04:09.234580        4.0          7.0   \n",
       "22688  2 months ago  2021-06-20 22:04:09.235577        4.0         93.0   \n",
       "\n",
       "                                             review_text  label lang  \\\n",
       "22684  (Translated by Google) Very beautiful park to ...      1   fr   \n",
       "22685  (Translated by Google) The people are all very...      1   fr   \n",
       "22686  (Translated by Google) Nice place to walk, jog...      1   fr   \n",
       "22687  (Translated by Google) Excellent food!\\n\\n(Ori...      1   fr   \n",
       "22688  (Translated by Google) I like to get some fres...      1   fr   \n",
       "\n",
       "                                             french_text  \n",
       "22684  Tres beau parc pour faire un pinic et profiter...  \n",
       "22685  Les gens sont tous très sociables.\\nExceptionnel.  \n",
       "22686  Belle place pour marcher, jogger, promener le ...  \n",
       "22687                            Nourriture excellente !  \n",
       "22688            J aime bien pour prendre de l air frais  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frenchReviewsDf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sum-stats\"></a> \n",
    "### 1.2 Calculating summary statistics \n",
    "The following section details the calculation of summary statistics including the number of words, special and uppercase characters per review. These values can then be used to compare if there is a significant difference between positive and negative reviews as well as if there are differences between English and French reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the number of words, special and uppercase characters per review\n",
    "\n",
    "parkReviews['word_count'] = [len(review.split()) for review in parkReviews['review_text']]\n",
    "\n",
    "parkReviews['uppercase_char_count'] = [sum(char.isupper() for char in review) \\\n",
    "                              for review in parkReviews['review_text']]                           \n",
    "\n",
    "parkReviews['special_char_count'] = [sum(char in string.punctuation for char in review) \\\n",
    "                            for review in parkReviews['review_text']]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "frenchReviewsDf['word_count'] = [len(review.split()) for review in frenchReviewsDf['french_text']]\n",
    "\n",
    "frenchReviewsDf['uppercase_char_count'] = [sum(char.isupper() for char in review) \\\n",
    "                              for review in frenchReviewsDf['french_text']]                           \n",
    "\n",
    "frenchReviewsDf['special_char_count'] = [sum(char in string.punctuation for char in review) \\\n",
    "                            for review in frenchReviewsDf['french_text']]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a breakdown of English positive and negative reviews\n",
    "pos_reviews = parkReviews[parkReviews['label'] == 1] \n",
    "neg_reviews = parkReviews[parkReviews['label'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a breakdown of French positive and negative reviews \n",
    "pos_reviewsFr = frenchReviewsDf[frenchReviewsDf['label'] == 1]\n",
    "neg_reviewsFr = frenchReviewsDf[frenchReviewsDf['label'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After breaking down the dataset into positive and negative reviews, one can take a look at the length of negative and positive reviews. There are 88.28% positive reviews, which means there is an unbalanced dataset. At the same time the length of reviews is not very different for negative and positive reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36920.000000\n",
       "mean        13.435049\n",
       "std         17.949938\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          8.000000\n",
       "75%         16.000000\n",
       "max        634.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4902.000000\n",
       "mean       15.740718\n",
       "std        21.407586\n",
       "min         1.000000\n",
       "25%         4.000000\n",
       "50%         9.000000\n",
       "75%        19.000000\n",
       "max       490.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviews['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8827889627468797"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "36920/(4902 + 36920)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14635.000000\n",
       "mean        12.701537\n",
       "std         16.127711\n",
       "min          1.000000\n",
       "25%          4.000000\n",
       "50%          8.000000\n",
       "75%         15.000000\n",
       "max        474.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# positive word count for French reviews\n",
    "pos_reviewsFr['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2514.000000\n",
       "mean       16.305091\n",
       "std        19.940490\n",
       "min         1.000000\n",
       "25%         5.000000\n",
       "50%        10.000000\n",
       "75%        20.000000\n",
       "max       258.000000\n",
       "Name: word_count, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative reviews word count for French reviews\n",
    "neg_reviewsFr['word_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8534025307598111"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "14635/(14635 + 2514) # 85.3% positive reviews in French dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compare the number of uppercase letters used in the postive and negative reviews. As we can see there is no real difference between the two as well in both the English and French case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36920.000000\n",
       "mean         2.075433\n",
       "std          3.525758\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          2.000000\n",
       "max        259.000000\n",
       "Name: uppercase_char_count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews['uppercase_char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4902.000000\n",
       "mean        2.157487\n",
       "std         3.377507\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        87.000000\n",
       "Name: uppercase_char_count, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviews['uppercase_char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14635.000000\n",
       "mean         1.819542\n",
       "std          2.511317\n",
       "min          0.000000\n",
       "25%          1.000000\n",
       "50%          1.000000\n",
       "75%          2.000000\n",
       "max        107.000000\n",
       "Name: uppercase_char_count, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviewsFr['uppercase_char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2514.000000\n",
       "mean        2.029037\n",
       "std         3.391481\n",
       "min         0.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         2.000000\n",
       "max        80.000000\n",
       "Name: uppercase_char_count, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviewsFr['uppercase_char_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally let's take a look at the special characters present in the positive and negativve group of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    36920.000000\n",
       "mean         2.111430\n",
       "std          3.324735\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          3.000000\n",
       "max        135.000000\n",
       "Name: special_char_count, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviews['special_char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4902.000000\n",
       "mean        2.436557\n",
       "std         4.232427\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         1.000000\n",
       "75%         3.000000\n",
       "max       109.000000\n",
       "Name: special_char_count, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviews['special_char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    14635.000000\n",
       "mean         2.345268\n",
       "std          3.710336\n",
       "min          0.000000\n",
       "25%          0.000000\n",
       "50%          1.000000\n",
       "75%          3.000000\n",
       "max         94.000000\n",
       "Name: special_char_count, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_reviewsFr['special_char_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2514.000000\n",
       "mean        2.945505\n",
       "std         4.274390\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         2.000000\n",
       "75%         4.000000\n",
       "max        63.000000\n",
       "Name: special_char_count, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_reviewsFr['special_char_count'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In general comparing the statistics between the positive and negative reviews there is no significant differences between the average length of reviews and number of special character counts. A more exact way to determine if there are any differences would be to perform a two sample t-test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"common-terms\"></a> \n",
    "### 1.3 Examining the most frequent words\n",
    "For both the English and French dataset, the most common words can be determined. By examining both dataset one can see that the most common words in both the positive and negative review categories the words are very simialar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreamock/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMostCommonWords(reviews, n_most_common, stopwords=None):\n",
    "    \n",
    "    '''Given a list of reviews, extracts the n most common words and if applicable removes stopwords. \n",
    "    A Counter object of the n most common words is returned'''\n",
    "    # flatten review column into a list of words, and set each to lowercase\n",
    "    flattened_reviews = [word for review in reviews for word in \\\n",
    "                         review.lower().split()]\n",
    "\n",
    "\n",
    "    # remove punctuation from reviews\n",
    "    flattened_reviews = [''.join(char for char in review if \\\n",
    "                                 char not in string.punctuation) for \\\n",
    "                         review in flattened_reviews]\n",
    "\n",
    "\n",
    "    # remove stopwords, if applicable\n",
    "    if stopwords:\n",
    "        flattened_reviews = [word for word in flattened_reviews if \\\n",
    "                             word not in stopwords]\n",
    "\n",
    "\n",
    "    # remove any empty strings that were created by this process\n",
    "    flattened_reviews = [review for review in flattened_reviews if review]\n",
    "\n",
    "    return Counter(flattened_reviews).most_common(n_most_common)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Most common words in English reviews\n",
    "The most common words in the positive and negative English reviews are very similar and contain a lot of stopwords. When performing the same process without stopwords allows to extract words that are more meaningful. In both cases one can see that the words in both the negative and positive review categories are very similar. One reason for this could be that the negative reviews include negations ie not beautiful but the negation is not included in the most common words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 23250),\n",
       " ('a', 17043),\n",
       " ('and', 16999),\n",
       " ('park', 15169),\n",
       " ('to', 13713),\n",
       " ('for', 11101),\n",
       " ('of', 10785),\n",
       " ('place', 8822),\n",
       " ('in', 8482),\n",
       " ('nice', 8142),\n",
       " ('beautiful', 7812),\n",
       " ('is', 7354),\n",
       " ('very', 6595),\n",
       " ('with', 6271),\n",
       " ('great', 5028)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words in positive English reviews\n",
    "getMostCommonWords(pos_reviews['review_text'], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4240),\n",
       " ('a', 2299),\n",
       " ('and', 2045),\n",
       " ('to', 1913),\n",
       " ('park', 1826),\n",
       " ('of', 1594),\n",
       " ('is', 1485),\n",
       " ('for', 1299),\n",
       " ('in', 1109),\n",
       " ('not', 1039),\n",
       " ('it', 991),\n",
       " ('but', 943),\n",
       " ('there', 789),\n",
       " ('nice', 723),\n",
       " ('i', 701)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words in negative English reviews\n",
    "getMostCommonWords(neg_reviews['review_text'], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('park', 15169),\n",
       " ('place', 8822),\n",
       " ('nice', 8142),\n",
       " ('beautiful', 7812),\n",
       " ('great', 5028),\n",
       " ('good', 3680),\n",
       " ('kids', 2177),\n",
       " ('walk', 2147),\n",
       " ('montreal', 2019),\n",
       " ('water', 1977)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostCommonWords(pos_reviews['review_text'], 10, stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('park', 1826),\n",
       " ('nice', 723),\n",
       " ('place', 686),\n",
       " ('beautiful', 446),\n",
       " ('good', 431),\n",
       " ('people', 357),\n",
       " ('small', 354),\n",
       " ('little', 301),\n",
       " ('children', 297),\n",
       " ('water', 277),\n",
       " ('kids', 261),\n",
       " ('many', 245),\n",
       " ('go', 233),\n",
       " ('great', 203),\n",
       " ('lot', 196)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostCommonWords(neg_reviews['review_text'], 15, stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Most common words in French reviews\n",
    "\n",
    "Similar to the most common words in English reviews the most common words involve a lot of common words. Even without stopwords the same patterns as with the English reviews pops up: the most common words in positive and negative reviews are very similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 8125),\n",
       " ('parc', 6350),\n",
       " ('pour', 6085),\n",
       " ('et', 5374),\n",
       " ('les', 3795),\n",
       " ('très', 3631),\n",
       " ('un', 3510),\n",
       " ('beau', 3264),\n",
       " ('la', 3110),\n",
       " ('le', 2947),\n",
       " ('des', 2541),\n",
       " ('en', 2281),\n",
       " ('à', 2241),\n",
       " ('avec', 1934),\n",
       " ('bien', 1706)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words in positive French reviews\n",
    "getMostCommonWords(pos_reviewsFr['french_text'], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 2048),\n",
       " ('parc', 1001),\n",
       " ('les', 930),\n",
       " ('et', 930),\n",
       " ('pour', 920),\n",
       " ('le', 811),\n",
       " ('pas', 736),\n",
       " ('la', 720),\n",
       " ('un', 666),\n",
       " ('des', 499),\n",
       " ('à', 496),\n",
       " ('a', 476),\n",
       " ('mais', 471),\n",
       " ('en', 433),\n",
       " ('il', 426)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common words in negative French reviews\n",
    "getMostCommonWords(neg_reviewsFr['french_text'], 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('parc', 6350),\n",
       " ('très', 3631),\n",
       " ('beau', 3264),\n",
       " ('bien', 1706),\n",
       " ('endroit', 1702),\n",
       " ('a', 1697),\n",
       " ('enfants', 1500),\n",
       " ('jeux', 1299),\n",
       " ('belle', 1267),\n",
       " ('cest', 1036)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostCommonWords(pos_reviewsFr['french_text'], 10, stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('parc', 1001),\n",
       " ('a', 476),\n",
       " ('très', 387),\n",
       " ('beau', 330),\n",
       " ('cest', 296),\n",
       " ('enfants', 278),\n",
       " ('bien', 269),\n",
       " ('petit', 225),\n",
       " ('beaucoup', 218),\n",
       " ('plus', 206),\n",
       " ('trop', 195),\n",
       " ('jeux', 192),\n",
       " ('endroit', 186),\n",
       " ('terrain', 174),\n",
       " ('peu', 160)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getMostCommonWords(neg_reviewsFr['french_text'], 15, stopwords.words('french'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"classifiers\"></a> \n",
    "\n",
    "## 2. Testing different classifiers\n",
    "The next step after having taken a look at the general dataset is to create a classifier that allows one to determine if a review is negative or positive. At the same time the accuracy of both English and French binary classification will be compared. As seen in the section below, the classifier in French language is less accurate than the English language one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Text vectorization \n",
    "Using the Tf-Idf Vectorizer the different words can be converted to feature vectors and weighted for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=15)\n",
    "bow = vectorizer.fit_transform(list(parkReviews['review_text']))\n",
    "labels = parkReviews['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41822, 2127)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '10',\n",
       " '100',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '15',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019',\n",
       " '2020',\n",
       " '2021',\n",
       " '25',\n",
       " '30',\n",
       " '45',\n",
       " '50',\n",
       " '67',\n",
       " 'abandoned',\n",
       " 'able',\n",
       " 'about',\n",
       " 'above',\n",
       " 'absolutely',\n",
       " 'access',\n",
       " 'accessible',\n",
       " 'accommodate',\n",
       " 'according',\n",
       " 'across',\n",
       " 'active',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actually',\n",
       " 'adapted',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'adds',\n",
       " 'adequate',\n",
       " 'adjacent',\n",
       " 'adjusted',\n",
       " 'admire',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adult',\n",
       " 'adults',\n",
       " 'advantage',\n",
       " 'advise',\n",
       " 'affordable',\n",
       " 'after',\n",
       " 'afternoon',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'ages',\n",
       " 'ago',\n",
       " 'air',\n",
       " 'alcohol',\n",
       " 'alike',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'allow',\n",
       " 'allowed',\n",
       " 'allows',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alot',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'amenities',\n",
       " 'among',\n",
       " 'amount',\n",
       " 'ample',\n",
       " 'amusement',\n",
       " 'an',\n",
       " 'and',\n",
       " 'angrignon',\n",
       " 'angus',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'anjou',\n",
       " 'annoying',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'apart',\n",
       " 'appointed',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'april',\n",
       " 'archery',\n",
       " 'architecture',\n",
       " 'are',\n",
       " 'area',\n",
       " 'areas',\n",
       " 'aren',\n",
       " 'arena',\n",
       " 'around',\n",
       " 'arranged',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'art',\n",
       " 'artificial',\n",
       " 'artists',\n",
       " 'as',\n",
       " 'ask',\n",
       " 'asphalt',\n",
       " 'at',\n",
       " 'athletes',\n",
       " 'atmosphere',\n",
       " 'attached',\n",
       " 'attend',\n",
       " 'attended',\n",
       " 'attention',\n",
       " 'attraction',\n",
       " 'attractions',\n",
       " 'attractive',\n",
       " 'au',\n",
       " 'august',\n",
       " 'autumn',\n",
       " 'available',\n",
       " 'avec',\n",
       " 'avenue',\n",
       " 'average',\n",
       " 'avoid',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'awsome',\n",
       " 'babies',\n",
       " 'baby',\n",
       " 'back',\n",
       " 'background',\n",
       " 'bad',\n",
       " 'badly',\n",
       " 'bags',\n",
       " 'ball',\n",
       " 'balls',\n",
       " 'bank',\n",
       " 'banks',\n",
       " 'bar',\n",
       " 'barbecue',\n",
       " 'barbecues',\n",
       " 'barbeque',\n",
       " 'barely',\n",
       " 'bars',\n",
       " 'base',\n",
       " 'baseball',\n",
       " 'basic',\n",
       " 'basket',\n",
       " 'basketball',\n",
       " 'bathing',\n",
       " 'bathroom',\n",
       " 'bathrooms',\n",
       " 'bbq',\n",
       " 'bbqs',\n",
       " 'bcp',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beau',\n",
       " 'beaucoup',\n",
       " 'beautiful',\n",
       " 'beautifull',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'beaver',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'beers',\n",
       " 'before',\n",
       " 'beginning',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'believe',\n",
       " 'belle',\n",
       " 'below',\n",
       " 'bench',\n",
       " 'benches',\n",
       " 'benefit',\n",
       " 'berri',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'best',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beware',\n",
       " 'bicycle',\n",
       " 'bicycles',\n",
       " 'bien',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bike',\n",
       " 'bikes',\n",
       " 'biking',\n",
       " 'bin',\n",
       " 'bins',\n",
       " 'biosphere',\n",
       " 'bird',\n",
       " 'birds',\n",
       " 'birthday',\n",
       " 'bit',\n",
       " 'bixi',\n",
       " 'black',\n",
       " 'blanket',\n",
       " 'blast',\n",
       " 'block',\n",
       " 'blocked',\n",
       " 'blocks',\n",
       " 'blue',\n",
       " 'blvd',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'boats',\n",
       " 'bocce',\n",
       " 'body',\n",
       " 'bonus',\n",
       " 'book',\n",
       " 'books',\n",
       " 'boring',\n",
       " 'borough',\n",
       " 'botanical',\n",
       " 'both',\n",
       " 'bottle',\n",
       " 'bottles',\n",
       " 'bottom',\n",
       " 'boulevard',\n",
       " 'bourassa',\n",
       " 'boy',\n",
       " 'boys',\n",
       " 'brand',\n",
       " 'bravo',\n",
       " 'break',\n",
       " 'breath',\n",
       " 'breathe',\n",
       " 'breathtaking',\n",
       " 'breeze',\n",
       " 'bridge',\n",
       " 'bridges',\n",
       " 'bright',\n",
       " 'bring',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'broken',\n",
       " 'brought',\n",
       " 'bug',\n",
       " 'bugs',\n",
       " 'building',\n",
       " 'buildings',\n",
       " 'built',\n",
       " 'bunch',\n",
       " 'bus',\n",
       " 'buses',\n",
       " 'business',\n",
       " 'bustle',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'butts',\n",
       " 'buy',\n",
       " 'by',\n",
       " 'cafe',\n",
       " 'cafes',\n",
       " 'café',\n",
       " 'calisthenics',\n",
       " 'call',\n",
       " 'called',\n",
       " 'calm',\n",
       " 'calming',\n",
       " 'came',\n",
       " 'camp',\n",
       " 'camping',\n",
       " 'can',\n",
       " 'canada',\n",
       " 'canadian',\n",
       " 'canal',\n",
       " 'cannot',\n",
       " 'cans',\n",
       " 'cap',\n",
       " 'car',\n",
       " 'card',\n",
       " 'care',\n",
       " 'careful',\n",
       " 'cars',\n",
       " 'cartier',\n",
       " 'case',\n",
       " 'casual',\n",
       " 'cat',\n",
       " 'catch',\n",
       " 'catherine',\n",
       " 'caught',\n",
       " 'cause',\n",
       " 'ce',\n",
       " 'celebrate',\n",
       " 'center',\n",
       " 'central',\n",
       " 'centre',\n",
       " 'certain',\n",
       " 'certainly',\n",
       " 'chair',\n",
       " 'chairs',\n",
       " 'chalet',\n",
       " 'chance',\n",
       " 'change',\n",
       " 'changed',\n",
       " 'changes',\n",
       " 'changing',\n",
       " 'charcoal',\n",
       " 'charge',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'chat',\n",
       " 'cheap',\n",
       " 'check',\n",
       " 'chemical',\n",
       " 'child',\n",
       " 'childhood',\n",
       " 'children',\n",
       " 'chill',\n",
       " 'chilling',\n",
       " 'choice',\n",
       " 'choices',\n",
       " 'choose',\n",
       " 'christmas',\n",
       " 'church',\n",
       " 'cigarette',\n",
       " 'circuit',\n",
       " 'circus',\n",
       " 'cirque',\n",
       " 'citizens',\n",
       " 'city',\n",
       " 'class',\n",
       " 'classes',\n",
       " 'classic',\n",
       " 'clean',\n",
       " 'cleaned',\n",
       " 'cleaner',\n",
       " 'cleaning',\n",
       " 'cleanliness',\n",
       " 'clear',\n",
       " 'cleared',\n",
       " 'clearly',\n",
       " 'climb',\n",
       " 'climbing',\n",
       " 'close',\n",
       " 'closed',\n",
       " 'closer',\n",
       " 'closest',\n",
       " 'club',\n",
       " 'coast',\n",
       " 'coffee',\n",
       " 'cohen',\n",
       " 'cold',\n",
       " 'color',\n",
       " 'colorful',\n",
       " 'colors',\n",
       " 'colours',\n",
       " 'come',\n",
       " 'comes',\n",
       " 'comfortable',\n",
       " 'coming',\n",
       " 'commercial',\n",
       " 'common',\n",
       " 'community',\n",
       " 'company',\n",
       " 'compared',\n",
       " 'complaint',\n",
       " 'complete',\n",
       " 'completely',\n",
       " 'complex',\n",
       " 'concept',\n",
       " 'concert',\n",
       " 'concerts',\n",
       " 'concrete',\n",
       " 'condition',\n",
       " 'congratulations',\n",
       " 'cons',\n",
       " 'considering',\n",
       " 'constantly',\n",
       " 'construction',\n",
       " 'contact',\n",
       " 'contains',\n",
       " 'contemplate',\n",
       " 'continue',\n",
       " 'convenience',\n",
       " 'convenient',\n",
       " 'cool',\n",
       " 'corner',\n",
       " 'corners',\n",
       " 'correct',\n",
       " 'cost',\n",
       " 'cote',\n",
       " 'cottage',\n",
       " 'could',\n",
       " 'couldn',\n",
       " 'country',\n",
       " 'countryside',\n",
       " 'couple',\n",
       " 'couples',\n",
       " 'course',\n",
       " 'court',\n",
       " 'courteous',\n",
       " 'courts',\n",
       " 'cover',\n",
       " 'covered',\n",
       " 'covid',\n",
       " 'covid19',\n",
       " 'cozy',\n",
       " 'crack',\n",
       " 'crazy',\n",
       " 'cream',\n",
       " 'create',\n",
       " 'created',\n",
       " 'cricket',\n",
       " 'cross',\n",
       " 'crosses',\n",
       " 'crossing',\n",
       " 'crowd',\n",
       " 'crowded',\n",
       " 'crowds',\n",
       " 'cultural',\n",
       " 'culture',\n",
       " 'cup',\n",
       " 'current',\n",
       " 'currently',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'cycle',\n",
       " 'cycling',\n",
       " 'cyclists',\n",
       " 'côte',\n",
       " 'daily',\n",
       " 'damaged',\n",
       " 'dame',\n",
       " 'dance',\n",
       " 'dancing',\n",
       " 'dangerous',\n",
       " 'dans',\n",
       " 'dark',\n",
       " 'date',\n",
       " 'daughter',\n",
       " 'daughters',\n",
       " 'day',\n",
       " 'daycare',\n",
       " 'days',\n",
       " 'de',\n",
       " 'dead',\n",
       " 'decent',\n",
       " 'decided',\n",
       " 'dedicated',\n",
       " 'deep',\n",
       " 'deer',\n",
       " 'definitely',\n",
       " 'delicious',\n",
       " 'denis',\n",
       " 'depending',\n",
       " 'des',\n",
       " 'deserves',\n",
       " 'design',\n",
       " 'designed',\n",
       " 'desired',\n",
       " 'despite',\n",
       " 'destination',\n",
       " 'destroyed',\n",
       " 'detour',\n",
       " 'development',\n",
       " 'diamond',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'difficult',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'direction',\n",
       " 'directly',\n",
       " 'dirt',\n",
       " 'dirty',\n",
       " 'disappointed',\n",
       " 'disappointing',\n",
       " 'discover',\n",
       " 'discovered',\n",
       " 'discovery',\n",
       " 'disgusting',\n",
       " 'distance',\n",
       " 'distancing',\n",
       " 'district',\n",
       " 'disturbing',\n",
       " 'diverse',\n",
       " 'diversity',\n",
       " 'divided',\n",
       " 'dj',\n",
       " 'do',\n",
       " 'dock',\n",
       " 'does',\n",
       " 'doesn',\n",
       " 'dog',\n",
       " 'doggy',\n",
       " 'dogs',\n",
       " 'doing',\n",
       " 'dollars',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'door',\n",
       " 'doors',\n",
       " 'down',\n",
       " 'downside',\n",
       " 'downtown',\n",
       " 'drapeau',\n",
       " 'dream',\n",
       " 'drink',\n",
       " 'drinking',\n",
       " 'drinks',\n",
       " 'drive',\n",
       " 'driving',\n",
       " 'drug',\n",
       " 'drugs',\n",
       " 'drunk',\n",
       " 'dry',\n",
       " 'du',\n",
       " 'duck',\n",
       " 'ducks',\n",
       " 'due',\n",
       " 'dump',\n",
       " 'during',\n",
       " 'each',\n",
       " 'early',\n",
       " 'earth',\n",
       " 'easier',\n",
       " 'easily',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'easy',\n",
       " 'eat',\n",
       " 'eating',\n",
       " 'eau',\n",
       " 'ect',\n",
       " 'edge',\n",
       " 'effort',\n",
       " 'either',\n",
       " 'elderly',\n",
       " 'electric',\n",
       " 'electronic',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'employees',\n",
       " 'empty',\n",
       " 'en',\n",
       " 'enchanting',\n",
       " 'enclosed',\n",
       " 'end',\n",
       " 'endroit',\n",
       " 'ends',\n",
       " 'energy',\n",
       " 'enfants',\n",
       " 'english',\n",
       " 'enjoy',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'enjoying',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entertaining',\n",
       " 'entertainment',\n",
       " 'entire',\n",
       " 'entrance',\n",
       " 'entry',\n",
       " 'environment',\n",
       " 'equipment',\n",
       " 'equipped',\n",
       " 'escape',\n",
       " 'especially',\n",
       " 'essential',\n",
       " 'est',\n",
       " 'et',\n",
       " 'etc',\n",
       " 'european',\n",
       " 'even',\n",
       " 'evening',\n",
       " 'evenings',\n",
       " 'event',\n",
       " 'events',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everybody',\n",
       " 'everyday',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'example',\n",
       " 'excellent',\n",
       " 'except',\n",
       " 'exceptional',\n",
       " 'exciting',\n",
       " 'exercise',\n",
       " 'exercises',\n",
       " 'exercising',\n",
       " 'exists',\n",
       " 'expect',\n",
       " 'expected',\n",
       " 'expensive',\n",
       " 'experience',\n",
       " 'explore',\n",
       " 'exploring',\n",
       " 'exposed',\n",
       " 'extra',\n",
       " 'extraordinary',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'fabulous',\n",
       " 'face',\n",
       " 'facilities',\n",
       " 'facility',\n",
       " 'facing',\n",
       " 'fact',\n",
       " 'fair',\n",
       " 'fairly',\n",
       " 'fall',\n",
       " 'falls',\n",
       " 'families',\n",
       " 'family',\n",
       " 'famous',\n",
       " 'fantastic',\n",
       " 'far',\n",
       " 'farm',\n",
       " 'fast',\n",
       " 'fauna',\n",
       " 'favorite',\n",
       " 'favourite',\n",
       " 'feature',\n",
       " 'features',\n",
       " 'fee',\n",
       " 'feed',\n",
       " 'feel',\n",
       " 'feeling',\n",
       " 'feels',\n",
       " 'feet',\n",
       " 'felt',\n",
       " 'fence',\n",
       " 'fenced',\n",
       " 'fences',\n",
       " 'festival',\n",
       " 'festivals',\n",
       " 'festive',\n",
       " 'few',\n",
       " 'fi',\n",
       " 'field',\n",
       " 'fields',\n",
       " 'fill',\n",
       " 'filled',\n",
       " 'finally',\n",
       " 'find',\n",
       " 'finding',\n",
       " 'fine',\n",
       " 'finish',\n",
       " 'finished',\n",
       " 'fire',\n",
       " 'fireworks',\n",
       " 'first',\n",
       " 'fish',\n",
       " 'fishing',\n",
       " 'fit',\n",
       " 'fitness',\n",
       " 'five',\n",
       " 'fixed',\n",
       " 'flat',\n",
       " 'flooded',\n",
       " 'floor',\n",
       " 'flora',\n",
       " 'flow',\n",
       " 'flower',\n",
       " 'flowers',\n",
       " 'fly',\n",
       " 'flying',\n",
       " 'foliage',\n",
       " 'follow',\n",
       " 'following',\n",
       " 'fontaine',\n",
       " 'food',\n",
       " 'foot',\n",
       " 'football',\n",
       " 'footbridge',\n",
       " 'for',\n",
       " 'forest',\n",
       " 'forget',\n",
       " 'form',\n",
       " 'former',\n",
       " 'forward',\n",
       " 'found',\n",
       " 'fountain',\n",
       " 'fountains',\n",
       " 'four',\n",
       " 'free',\n",
       " 'french',\n",
       " 'frequent',\n",
       " 'frequented',\n",
       " 'frequently',\n",
       " 'fresh',\n",
       " 'freshness',\n",
       " 'friday',\n",
       " 'friend',\n",
       " 'friendly',\n",
       " 'friends',\n",
       " 'frisbee',\n",
       " 'from',\n",
       " 'front',\n",
       " 'frozen',\n",
       " 'full',\n",
       " 'fully',\n",
       " 'fun',\n",
       " 'functional',\n",
       " 'funny',\n",
       " 'further',\n",
       " 'future',\n",
       " 'game',\n",
       " 'gamelin',\n",
       " 'games',\n",
       " 'garbage',\n",
       " 'garden',\n",
       " 'gardens',\n",
       " 'gas',\n",
       " 'gather',\n",
       " 'gathering',\n",
       " 'gatherings',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'gazebo',\n",
       " 'geese',\n",
       " 'gem',\n",
       " 'general',\n",
       " 'generally',\n",
       " 'get',\n",
       " 'getaway',\n",
       " 'gets',\n",
       " 'getting',\n",
       " 'giant',\n",
       " 'gift',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'given',\n",
       " 'gives',\n",
       " 'giving',\n",
       " 'glass',\n",
       " 'go',\n",
       " 'god',\n",
       " 'goes',\n",
       " 'going',\n",
       " 'golf',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'google',\n",
       " 'goose',\n",
       " 'gorgeous',\n",
       " 'got',\n",
       " 'gouin',\n",
       " 'grab',\n",
       " 'grand',\n",
       " 'grass',\n",
       " 'grassy',\n",
       " 'gravel',\n",
       " 'great',\n",
       " 'greatest',\n",
       " 'greatly',\n",
       " 'green',\n",
       " 'greenery',\n",
       " 'grew',\n",
       " 'grills',\n",
       " 'grocery',\n",
       " 'groomed',\n",
       " 'ground',\n",
       " 'grounds',\n",
       " 'group',\n",
       " 'groups',\n",
       " 'growing',\n",
       " 'grown',\n",
       " 'guess',\n",
       " 'guide',\n",
       " 'guy',\n",
       " 'guys',\n",
       " 'gym',\n",
       " 'had',\n",
       " 'half',\n",
       " 'hall',\n",
       " 'hammock',\n",
       " 'hammocks',\n",
       " 'hand',\n",
       " 'hands',\n",
       " 'handsome',\n",
       " 'hang',\n",
       " 'hanging',\n",
       " 'hangout',\n",
       " 'happen',\n",
       " 'happened',\n",
       " 'happening',\n",
       " 'happens',\n",
       " 'happiness',\n",
       " 'happy',\n",
       " 'hard',\n",
       " 'has',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'having',\n",
       " 'he',\n",
       " 'head',\n",
       " 'health',\n",
       " 'healthy',\n",
       " 'hear',\n",
       " 'heart',\n",
       " 'heat',\n",
       " 'heated',\n",
       " 'heaven',\n",
       " 'heavy',\n",
       " 'height',\n",
       " 'held',\n",
       " 'help',\n",
       " 'helpful',\n",
       " 'henri',\n",
       " 'her',\n",
       " 'here',\n",
       " 'heritage',\n",
       " 'hey',\n",
       " 'hidden',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'highway',\n",
       " 'hike',\n",
       " 'hikes',\n",
       " 'hiking',\n",
       " 'hill',\n",
       " 'hills',\n",
       " 'him',\n",
       " 'his',\n",
       " 'historic',\n",
       " 'historical',\n",
       " 'history',\n",
       " 'hit',\n",
       " 'hochelaga',\n",
       " 'hockey',\n",
       " 'hold',\n",
       " 'hole',\n",
       " 'holes',\n",
       " 'home',\n",
       " 'homeless',\n",
       " 'homes',\n",
       " 'hope',\n",
       " 'horrible',\n",
       " 'host',\n",
       " 'hosts',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hours',\n",
       " 'house',\n",
       " 'houses',\n",
       " 'how',\n",
       " 'however',\n",
       " 'huge',\n",
       " 'human',\n",
       " 'humans',\n",
       " 'hustle',\n",
       " 'ice',\n",
       " 'iconic',\n",
       " 'icy',\n",
       " 'idea',\n",
       " 'ideal',\n",
       " 'if',\n",
       " 'il',\n",
       " 'ile',\n",
       " 'imagine',\n",
       " 'important',\n",
       " 'impossible',\n",
       " 'impressed',\n",
       " 'impression',\n",
       " 'impressive',\n",
       " 'improve',\n",
       " 'improved',\n",
       " 'improvement',\n",
       " 'improvements',\n",
       " 'in',\n",
       " 'includes',\n",
       " 'including',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'indoor',\n",
       " 'industrial',\n",
       " 'information',\n",
       " 'infrastructure',\n",
       " 'inner',\n",
       " 'insects',\n",
       " 'inside',\n",
       " 'install',\n",
       " 'installation',\n",
       " 'installations',\n",
       " 'installed',\n",
       " 'instead',\n",
       " 'interest',\n",
       " 'interesting',\n",
       " 'internet',\n",
       " 'intimate',\n",
       " 'into',\n",
       " 'inviting',\n",
       " 'is',\n",
       " 'island',\n",
       " 'islands',\n",
       " 'isn',\n",
       " 'issue',\n",
       " 'it',\n",
       " 'italian',\n",
       " 'italy',\n",
       " 'items',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'jacques',\n",
       " 'jarry',\n",
       " 'jean',\n",
       " 'jet',\n",
       " 'jets',\n",
       " 'jeux',\n",
       " 'jewel',\n",
       " 'job',\n",
       " 'jog',\n",
       " 'joggers',\n",
       " 'jogging',\n",
       " 'joseph',\n",
       " 'joy',\n",
       " 'july',\n",
       " 'june',\n",
       " 'jungle',\n",
       " 'junkies',\n",
       " 'just',\n",
       " 'kayak',\n",
       " 'keep',\n",
       " 'keeping',\n",
       " 'kept',\n",
       " 'kick',\n",
       " 'kid',\n",
       " 'kiddie',\n",
       " 'kids',\n",
       " 'kind',\n",
       " 'kinda',\n",
       " 'kinds',\n",
       " 'kiosk',\n",
       " 'kite',\n",
       " 'km',\n",
       " 'know',\n",
       " 'known',\n",
       " 'la',\n",
       " 'lac',\n",
       " 'lachine',\n",
       " 'lack',\n",
       " 'lacking',\n",
       " 'lacks',\n",
       " 'lady',\n",
       " 'lafontaine',\n",
       " 'laid',\n",
       " 'lake',\n",
       " 'lakes',\n",
       " 'land',\n",
       " 'landscape',\n",
       " 'landscaped',\n",
       " 'landscapes',\n",
       " 'landscaping',\n",
       " 'lane',\n",
       " 'lanes',\n",
       " 'large',\n",
       " 'larger',\n",
       " 'largest',\n",
       " 'lasalle',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'laurence',\n",
       " 'laurent',\n",
       " 'laurier',\n",
       " 'laval',\n",
       " 'lawn',\n",
       " 'lawns',\n",
       " 'lawrence',\n",
       " 'lay',\n",
       " 'layout',\n",
       " 'le',\n",
       " 'leading',\n",
       " ...]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# names of features\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2127"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total number of features\n",
    "len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2007442684284577"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dictionary of features and tfidf scores\n",
    "tfidfDict = dict(zip(vectorizer.get_feature_names(), bow.toarray()[0]))\n",
    "tfidfDict['appreciated'] # sample score for a words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe that contains \n",
    "featureDf = pd.DataFrame.from_dict(tfidfDict, \n",
    "                                   orient='index', columns=['tfidf'])\n",
    "featureDf.reset_index(inplace=True)\n",
    "featureDf = featureDf.rename(columns = {'index':'feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1895</th>\n",
       "      <td>today</td>\n",
       "      <td>0.183384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>0.190613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>nicest</td>\n",
       "      <td>0.196902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1302</th>\n",
       "      <td>pandemic</td>\n",
       "      <td>0.199586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>appreciated</td>\n",
       "      <td>0.200744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>points</td>\n",
       "      <td>0.208271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>promenade</td>\n",
       "      <td>0.215600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1101</th>\n",
       "      <td>mask</td>\n",
       "      <td>0.220245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>584</th>\n",
       "      <td>entry</td>\n",
       "      <td>0.221551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>inviting</td>\n",
       "      <td>0.222929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature     tfidf\n",
       "1895        today  0.183384\n",
       "575     enjoyable  0.190613\n",
       "1214       nicest  0.196902\n",
       "1302     pandemic  0.199586\n",
       "105   appreciated  0.200744\n",
       "1397       points  0.208271\n",
       "1445    promenade  0.215600\n",
       "1101         mask  0.220245\n",
       "584         entry  0.221551\n",
       "918      inviting  0.222929"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featureDf.sort_values('tfidf')[-10:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the words that have the highest tfidf score in the positive and negative sentiment datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_pos = TfidfVectorizer(min_df=15)\n",
    "bow_pos = vectorizer_pos.fit_transform(list(pos_reviews['review_text']))\n",
    "labels_pos = pos_reviews['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_neg = TfidfVectorizer(min_df=15)\n",
    "bow_neg = vectorizer_neg.fit_transform(list(neg_reviews['review_text']))\n",
    "labels_neg = neg_reviews['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfDictPos = dict(zip(vectorizer_pos.get_feature_names(), bow_pos.toarray()[0]))\n",
    "tfidfDictNeg = dict(zip(vectorizer_neg.get_feature_names(), bow_neg.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "posFeatureDf = pd.DataFrame.from_dict(tfidfDictPos, \n",
    "                                   orient='index', columns=['tfidf'])\n",
    "posFeatureDf.reset_index(inplace=True)\n",
    "posFeatureDf = posFeatureDf.rename(columns = {'index':'feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "negFeatureDf = pd.DataFrame.from_dict(tfidfDictNeg, \n",
    "                                   orient='index', columns=['tfidf'])\n",
    "negFeatureDf.reset_index(inplace=True)\n",
    "negFeatureDf = negFeatureDf.rename(columns = {'index':'feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>the</td>\n",
       "      <td>0.175157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>toilet</td>\n",
       "      <td>0.178911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>chalet</td>\n",
       "      <td>0.183008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>forget</td>\n",
       "      <td>0.184969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>lawrence</td>\n",
       "      <td>0.187326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>offers</td>\n",
       "      <td>0.188328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764</th>\n",
       "      <td>waterfront</td>\n",
       "      <td>0.196256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>this</td>\n",
       "      <td>0.198067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1639</th>\n",
       "      <td>today</td>\n",
       "      <td>0.201076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>enjoyable</td>\n",
       "      <td>0.202747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>nicest</td>\n",
       "      <td>0.210674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>appreciated</td>\n",
       "      <td>0.217112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>pandemic</td>\n",
       "      <td>0.218602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>points</td>\n",
       "      <td>0.222722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1244</th>\n",
       "      <td>promenade</td>\n",
       "      <td>0.233454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature     tfidf\n",
       "1611          the  0.175157\n",
       "1643       toilet  0.178911\n",
       "284        chalet  0.183008\n",
       "605        forget  0.184969\n",
       "862      lawrence  0.187326\n",
       "1077       offers  0.188328\n",
       "1764   waterfront  0.196256\n",
       "1624         this  0.198067\n",
       "1639        today  0.201076\n",
       "492     enjoyable  0.202747\n",
       "1052       nicest  0.210674\n",
       "94    appreciated  0.217112\n",
       "1127     pandemic  0.218602\n",
       "1210       points  0.222722\n",
       "1244    promenade  0.233454"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posFeatureDf.sort_values('tfidf')[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>friendly</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>friends</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>from</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>free</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>the</td>\n",
       "      <td>0.127299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>to</td>\n",
       "      <td>0.154861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>you</td>\n",
       "      <td>0.243902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>have</td>\n",
       "      <td>0.251447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>if</td>\n",
       "      <td>0.277831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>by</td>\n",
       "      <td>0.282278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>ok</td>\n",
       "      <td>0.299108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>its</td>\n",
       "      <td>0.314444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>want</td>\n",
       "      <td>0.366955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>st</td>\n",
       "      <td>0.399077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>beer</td>\n",
       "      <td>0.444937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     tfidf\n",
       "188  friendly  0.000000\n",
       "189   friends  0.000000\n",
       "190      from  0.000000\n",
       "187      free  0.000000\n",
       "481       the  0.127299\n",
       "498        to  0.154861\n",
       "567       you  0.243902\n",
       "215      have  0.251447\n",
       "232        if  0.277831\n",
       "71         by  0.282278\n",
       "325        ok  0.299108\n",
       "242       its  0.314444\n",
       "531      want  0.366955\n",
       "454        st  0.399077\n",
       "52       beer  0.444937"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negFeatureDf.sort_values('tfidf')[-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 200 best features \n",
    "selected_features = SelectKBest(chi2, k=200).fit(bow, labels).get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41822x200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use selected features for vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=15, vocabulary=selected_features)\n",
    "\n",
    "bow2 = vectorizer.fit_transform(list(parkReviews['review_text']))\n",
    "bow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(bow, labels, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28020, 2127)\n",
      "(13802, 2127)\n",
      "(28020,)\n",
      "(13802,)\n"
     ]
    }
   ],
   "source": [
    "# check out the dataset \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Text vectorization of French reviews\n",
    "Similar to the English reviews, one can use text vectorization to pre-process the French reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizerFr = TfidfVectorizer(min_df=15)\n",
    "bowFr = vectorizerFr.fit_transform(list(frenchReviewsDf['french_text']))\n",
    "labelsFr = frenchReviewsDf['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17149, 1180)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bowFr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1180"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizerFr.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfDictFr = dict(zip(vectorizerFr.get_feature_names(), bow.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidfDictFr['améliorer'] # tfidif score of a french word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureDfFr = pd.DataFrame.from_dict(tfidfDictFr, \n",
    "                                   orient='index', columns=['tfidf'])\n",
    "featureDfFr.reset_index(inplace=True)\n",
    "featureDfFr = featureDfFr.rename(columns = {'index':'feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>827</th>\n",
       "      <td>pour</td>\n",
       "      <td>0.162610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>et</td>\n",
       "      <td>0.173683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>beau</td>\n",
       "      <td>0.197146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1089</th>\n",
       "      <td>un</td>\n",
       "      <td>0.200496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>faire</td>\n",
       "      <td>0.308118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>de</td>\n",
       "      <td>0.313332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>tres</td>\n",
       "      <td>0.359868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>nature</td>\n",
       "      <td>0.371318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>la</td>\n",
       "      <td>0.425115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>profiter</td>\n",
       "      <td>0.447984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature     tfidf\n",
       "827       pour  0.162610\n",
       "379         et  0.173683\n",
       "152       beau  0.197146\n",
       "1089        un  0.200496\n",
       "398      faire  0.308118\n",
       "295         de  0.313332\n",
       "1079      tres  0.359868\n",
       "664     nature  0.371318\n",
       "558         la  0.425115\n",
       "848   profiter  0.447984"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words with highest tfidf scores\n",
    "featureDfFr.sort_values('tfidf')[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can take a look at the words that have the highest tfidf score in the positive and negative sentiment datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_posFr = TfidfVectorizer(min_df=15)\n",
    "bow_posFr = vectorizer_posFr.fit_transform(list(pos_reviewsFr['french_text']))\n",
    "labels_posFr = pos_reviewsFr['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_negFr = TfidfVectorizer(min_df=15)\n",
    "bow_negFr = vectorizer_negFr.fit_transform(list(neg_reviewsFr['french_text']))\n",
    "labels_negFr = neg_reviewsFr['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfDictPosFr = dict(zip(vectorizer_posFr.get_feature_names(), bow_posFr.toarray()[0]))\n",
    "tfidfDictNegFr = dict(zip(vectorizer_negFr.get_feature_names(), bow_negFr.toarray()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "posFeatureFrDf = pd.DataFrame.from_dict(tfidfDictPosFr, \n",
    "                                   orient='index', columns=['tfidf'])\n",
    "posFeatureFrDf.reset_index(inplace=True)\n",
    "posFeatureFrDf = posFeatureFrDf.rename(columns = {'index':'feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "negFeatureFrDf = pd.DataFrame.from_dict(tfidfDictNegFr, \n",
    "                                   orient='index', columns=['tfidf'])\n",
    "negFeatureFrDf.reset_index(inplace=True)\n",
    "negFeatureFrDf = negFeatureFrDf.rename(columns = {'index':'feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>faites</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340</th>\n",
       "      <td>familial</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>eu</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>ete</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>parc</td>\n",
       "      <td>0.149239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>712</th>\n",
       "      <td>pour</td>\n",
       "      <td>0.161498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>et</td>\n",
       "      <td>0.173906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>beau</td>\n",
       "      <td>0.193378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>un</td>\n",
       "      <td>0.202580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>faire</td>\n",
       "      <td>0.309099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>de</td>\n",
       "      <td>0.323187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>tres</td>\n",
       "      <td>0.356667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>nature</td>\n",
       "      <td>0.365215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>la</td>\n",
       "      <td>0.432156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>profiter</td>\n",
       "      <td>0.442295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     tfidf\n",
       "339    faites  0.000000\n",
       "340  familial  0.000000\n",
       "323        eu  0.000000\n",
       "322       ete  0.000000\n",
       "625      parc  0.149239\n",
       "712      pour  0.161498\n",
       "320        et  0.173906\n",
       "129      beau  0.193378\n",
       "930        un  0.202580\n",
       "336     faire  0.309099\n",
       "254        de  0.323187\n",
       "922      tres  0.356667\n",
       "571    nature  0.365215\n",
       "472        la  0.432156\n",
       "729  profiter  0.442295"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posFeatureFrDf.sort_values('tfidf')[-15:] # words with highest tfidif words in positive reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>gens</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>gazon</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>fait</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>être</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>fontaine</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>font</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>fois</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>fleuve</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>fin</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>fermé</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>faut</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>football</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>de</td>\n",
       "      <td>0.254753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>trop</td>\n",
       "      <td>0.515403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>sentier</td>\n",
       "      <td>0.818206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature     tfidf\n",
       "108      gens  0.000000\n",
       "107     gazon  0.000000\n",
       "97       fait  0.000000\n",
       "313      être  0.000000\n",
       "105  fontaine  0.000000\n",
       "104      font  0.000000\n",
       "103      fois  0.000000\n",
       "102    fleuve  0.000000\n",
       "101       fin  0.000000\n",
       "100     fermé  0.000000\n",
       "99       faut  0.000000\n",
       "106  football  0.000000\n",
       "68         de  0.254753\n",
       "288      trop  0.515403\n",
       "241   sentier  0.818206"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negFeatureFrDf.sort_values('tfidf')[-15:] # words with highest tfidif words in negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select 200 best features \n",
    "selected_features = SelectKBest(chi2, k=200).fit(bowFr, labelsFr).get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<41822x200 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 0 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use selected features for vectorizer\n",
    "vectorizer = TfidfVectorizer(min_df=15, vocabulary=selected_features)\n",
    "\n",
    "bow2 = vectorizer.fit_transform(list(parkReviews['review_text']))\n",
    "bow2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trainFr, X_testFr, y_trainFr, y_testFr = train_test_split(bowFr, labelsFr, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11489, 1180)\n",
      "(5660, 1180)\n",
      "(11489,)\n",
      "(5660,)\n"
     ]
    }
   ],
   "source": [
    "# check out the dataset \n",
    "print(X_trainFr.shape)\n",
    "print(X_testFr.shape)\n",
    "print(y_trainFr.shape)\n",
    "print(y_testFr.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"test-class\"></a> \n",
    "## 2.2 Testing various classifiers \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Random Forest classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958846543979133"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = rfc()\n",
    "classifier.fit(X_train,y_train)\n",
    "classifier.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8740282685512367"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# random forest classifier on french reviews\n",
    "classifierFr = rfc()\n",
    "classifierFr.fit(X_trainFr,y_trainFr)\n",
    "classifierFr.score(X_testFr,y_testFr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8871902622808289\n",
      "score on train: 0.9016773733047823\n",
      "CPU times: user 1 s, sys: 77.9 ms, total: 1.08 s\n",
      "Wall time: 3.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clfdt = DecisionTreeClassifier(min_samples_split=30,max_depth=10)\n",
    "clfdt.fit(X_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \"  + str(clfdt.score(X_test, y_test)))\n",
    "print(\"score on train: \" + str(clfdt.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (11489, 1180)\n",
      "score on test: 0.8643109540636043\n",
      "score on train: 0.8885890852119419\n",
      "CPU times: user 200 ms, sys: 13.1 ms, total: 213 ms\n",
      "Wall time: 228 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "clfdtFr = DecisionTreeClassifier(min_samples_split=30,max_depth=10)\n",
    "clfdtFr.fit(X_trainFr, y_trainFr)\n",
    "\n",
    "print(\"train shape: \" + str(X_trainFr.shape))\n",
    "print(\"score on test: \"  + str(clfdt.score(X_testFr, y_testFr)))\n",
    "print(\"score on train: \" + str(clfdt.score(X_trainFr, y_trainFr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8836400521663527\n",
      "score on train: 0.8860099928622412\n",
      "CPU times: user 1.61 s, sys: 125 ms, total: 1.73 s\n",
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bg=BaggingClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=3),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bg.fit(X_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(bg.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(bg.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (11489, 1180)\n",
      "score on test: 0.8591872791519435\n",
      "score on train: 0.8603881974062146\n",
      "CPU times: user 463 ms, sys: 14.3 ms, total: 477 ms\n",
      "Wall time: 507 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "bgFr=BaggingClassifier(DecisionTreeClassifier(min_samples_split=10,max_depth=3),max_samples=0.5,max_features=1.0,n_estimators=10)\n",
    "bgFr.fit(X_trainFr, y_trainFr)\n",
    "\n",
    "print(\"train shape: \" + str(X_trainFr.shape))\n",
    "print(\"score on test: \" + str(bgFr.score(X_testFr, y_testFr)))\n",
    "print(\"score on train: \"+ str(bgFr.score(X_trainFr, y_trainFr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8921170844805101\n",
      "score on train: 0.9065310492505353\n"
     ]
    }
   ],
   "source": [
    "# boosting decision tree\n",
    "\n",
    "adb = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),n_estimators=100,learning_rate=0.5)\n",
    "adb.fit(X_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(adb.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(adb.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (11489, 1180)\n",
      "score on test: 0.8743816254416961\n",
      "score on train: 0.8938114718426321\n"
     ]
    }
   ],
   "source": [
    "# boosting decision tree with french reviews\n",
    "\n",
    "adbFr = AdaBoostClassifier(DecisionTreeClassifier(max_depth=2),n_estimators=100,learning_rate=0.5)\n",
    "adbFr.fit(X_trainFr, y_trainFr)\n",
    "\n",
    "print(\"train shape: \" + str(X_trainFr.shape))\n",
    "print(\"score on test: \" + str(adbFr.score(X_testFr, y_testFr)))\n",
    "print(\"score on train: \"+ str(adbFr.score(X_trainFr, y_trainFr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.8 ms, sys: 35.7 ms, total: 55.5 ms\n",
      "Wall time: 299 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mnb = MultinomialNB().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8926242573540066\n",
      "score on train: 0.8975374732334047\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(mnb.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(mnb.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.85 ms, sys: 11.9 ms, total: 18.7 ms\n",
      "Wall time: 36.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time # classification on French reviews\n",
    "mnbFr = MultinomialNB().fit(X_trainFr, y_trainFr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (11489, 1180)\n",
      "score on test: 0.873321554770318\n",
      "score on train: 0.8766646357385325\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \" + str(X_trainFr.shape))\n",
    "print(\"score on test: \" + str(mnbFr.score(X_testFr, y_testFr)))\n",
    "print(\"score on train: \"+ str(mnbFr.score(X_trainFr, y_trainFr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 333 ms, sys: 42.2 ms, total: 375 ms\n",
      "Wall time: 489 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lr=LogisticRegression(max_iter=5000)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8945080423127083\n",
      "score on train: 0.9053533190578158\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(lr.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(lr.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 68 ms, sys: 5.54 ms, total: 73.5 ms\n",
      "Wall time: 83.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#logistic regression with stochastic gradient decent\n",
    "sgd=SGDClassifier()\n",
    "sgd.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8908129256629475\n",
      "score on train: 0.8955745895788723\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(sgd.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(sgd.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of the French reviews the accuracy is slightly lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 513 ms, sys: 69.2 ms, total: 582 ms\n",
      "Wall time: 757 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=5000)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "lrFr=LogisticRegression(max_iter=5000)\n",
    "lrFr.fit(X_trainFr, y_trainFr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (11489, 1180)\n",
      "score on test: 0.8763250883392226\n",
      "score on train: 0.881016624597441\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \" + str(X_trainFr.shape))\n",
    "print(\"score on test: \" + str(lrFr.score(X_testFr, y_testFr)))\n",
    "print(\"score on train: \"+ str(lrFr.score(X_trainFr, y_trainFr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.7 ms, sys: 7.11 ms, total: 32.9 ms\n",
      "Wall time: 43.3 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#logistic regression with stochastic gradient decent\n",
    "sgdFr=SGDClassifier()\n",
    "sgdFr.fit(X_trainFr, y_trainFr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (11489, 1180)\n",
      "score on test: 0.876678445229682\n",
      "score on train: 0.8839759770214988\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \" + str(X_trainFr.shape))\n",
    "print(\"score on test: \" + str(sgdFr.score(X_testFr, y_testFr)))\n",
    "print(\"score on train: \"+ str(sgdFr.score(X_trainFr, y_trainFr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 K-nearest neighbors\n",
    "A k-nearest neighbors classifier is trained on the English and French reviews. In the case of the English reviews the score on the test set is around 87.47% and for the French reviews it is 84.54%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (28020, 2127)\n",
      "score on test: 0.8747283002463411\n",
      "score on train: 0.9011063526052819\n",
      "CPU times: user 2min 37s, sys: 3min 47s, total: 6min 25s\n",
      "Wall time: 20min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=5,algorithm = 'ball_tree')\n",
    "knn = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"train shape: \" + str(X_train.shape))\n",
    "print(\"score on test: \" + str(knn.score(X_test, y_test)))\n",
    "print(\"score on train: \"+ str(knn.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (11489, 1180)\n",
      "score on test: 0.8454063604240283\n",
      "score on train: 0.876403516406998\n",
      "CPU times: user 21.9 s, sys: 12.5 s, total: 34.3 s\n",
      "Wall time: 32.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# knn on french reviews\n",
    "knnFr = KNeighborsClassifier(algorithm = 'brute', n_jobs=-1)\n",
    "\n",
    "knnFr.fit(X_trainFr, y_trainFr)\n",
    "\n",
    "print(\"train shape: \" + str(X_trainFr.shape))\n",
    "print(\"score on test: \" + str(knnFr.score(X_testFr, y_testFr)))\n",
    "print(\"score on train: \"+ str(knnFr.score(X_trainFr, y_trainFr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 RNN for classification\n",
    "An RNN can be used to take the more information into account. The following is an initial try of using an RNN. This is just a beginning and has to be explored further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(allReviewEn, test_size = 0.3, random_state=42)\n",
    "\n",
    "# clean the indexing\n",
    "train.reset_index(drop=True),test.reset_index(drop=True)\n",
    "\n",
    "# save train and test in csv files \n",
    "train[['review_text', 'label']].to_csv('all_en_train.csv', index=False)\n",
    "test[['review_text', 'label']].to_csv('all_en_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using Torchtest to processs text data\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import torch \n",
    "import torchtext\n",
    "\n",
    "from torchtext.legacy.data import Field, BucketIterator, TabularDataset, LabelField\n",
    "\n",
    "import nltk \n",
    "nltk.download('punkt') # for punkt tokenizer\n",
    "\n",
    "from nltk import word_tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtext field parameter specifies how data should be processed, here tokenized\n",
    "TEXT = Field(tokenize = word_tokenize)\n",
    "\n",
    "LABEL = LabelField(dtype = torch.float) # convert \n",
    "\n",
    "datafields = [ ('review_text', TEXT), ('label', LABEL)] \n",
    "\n",
    "# specify what data that will work with, split to train and text, map to field \n",
    "trn, tst = TabularDataset.splits(path = '/Users/andreamock/Documents/review_datasets',\n",
    "                               train = 'all_en_train.csv', test = 'all_en_test.csv', format = 'csv',\n",
    "                               skip_header = True, fields = datafields)\n",
    "\n",
    "\n",
    "# training examples \n",
    "trn[:5]\n",
    "\n",
    "print(f'Number of training examples: {len(trn)}')\n",
    "print(f'Number of testing examples: {len(tst)}')\n",
    "\n",
    "# each example has label and text\n",
    "trn[5].__dict__.keys()\n",
    "\n",
    "trn[1].review_text # text has been tokenized in individual words\n",
    "\n",
    "trn[1].label\n",
    "\n",
    "# limit size of feature vectors to 15000, use one-encoding to get the top 15000 words in vocab\n",
    "TEXT.build_vocab(trn, max_size = 15000)\n",
    "\n",
    "LABEL.build_vocab(trn)\n",
    "\n",
    "print(f'Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}')\n",
    "print(f'Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}')\n",
    "# two additional tokens were added to vocab, one for unknown words and another for padding to make sentences equal lengths\n",
    "\n",
    "print(TEXT.vocab.freqs.most_common(50)) \n",
    "\n",
    "print(TEXT.vocab.itos[:10]) # integer to string mapping 0 and 1 to unknown and padding\n",
    "\n",
    "batch_size = 64 \n",
    "\n",
    "# returns a batch of examples where each example is of similar length (thus minimizing padding for each example)\n",
    "train_iterator, test_iterator = BucketIterator.splits(\n",
    "    (trn,tst), batch_size = batch_size, sort_key = lambda x: len(x.review_text), sort_within_batch = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Designing an RNN for binary text classification \n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        # input_dim = input dimensions of words \n",
    "        # embedding_dim = dimension of word embeddings, dense word representation for training RNN\n",
    "        # hidden_dim = dimension of hidden state of RNN\n",
    "        # output_dim = output dimensions of RNN output\n",
    "        \n",
    "        super().__init__()\n",
    "        #  convert one-hot encoded sentences to dense format using embeddings to represent each word\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        # input to rnn is current word's embedding and previous hidden state, one word per time instance (memory cell)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        # fully connected layer to classify as positive or negative \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        # input sentence (list of indexes of one hot encoded words) is represented using its embedding\n",
    "        embedded = self.embedding(text)\n",
    "        \n",
    "        embedded_dropout = self.dropout(embedded)\n",
    "        \n",
    "        # output = concatentation of hidden state for every time step (ie word) [sentence length, batch size, hiddendim]\n",
    "        # hidden = final hidden state fed into linear layer\n",
    "        output, (hidden, _) = self.rnn(embedded_dropout)\n",
    "        \n",
    "        hidden_1D = hidden.squeeze(0) # get rid of unnecessary dimension \n",
    "        \n",
    "        assert torch.equal(output[-1, :, :], hidden_1D) # confirm that it is indeed last hidden state \n",
    "        \n",
    "        return self.fc(hidden_1D) # last hidden state fed into fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting dimensions \n",
    "input_dim = len(TEXT.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 256\n",
    "output_dim=1\n",
    "\n",
    "model = RNN(input_dim, embedding_dim, hidden_dim, output_dim)\n",
    "\n",
    "model # see what our model looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with optimizer\n",
    "import torch.optim as optim \n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-6)\n",
    "\n",
    "# binary cross entropy with logits (cross-entropy for binary classification, \n",
    "# w/ sigmoid activation func to predict in range of 0 and 1)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion): # helper function for training process\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for batch in iterator:  # iterator over all batches of training data\n",
    "        \n",
    "        optimizer.zero_grad() # zero out gradients of optimizer\n",
    "                \n",
    "        predictions = model(batch.review_text).squeeze(1) # make predictions, squeeze to be 1d instead of [, ]\n",
    "        \n",
    "        loss = criterion(predictions, batch.label) # calculate loss\n",
    "        \n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        correct = (rounded_preds == batch.label).float() # how many were correct\n",
    "        \n",
    "        acc = correct.sum() / len(correct)\n",
    "        \n",
    "        loss.backward() # backward pass on rnn\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item() # keep track of epoch loss and accuracy\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "    print(f' Epoch: {epoch+1}, Train loss: {train_loss}, Train Acc: {train_acc*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the accuracy on our test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't want to update the parameters when evaluating the accuracy\n",
    "epoch_loss = 0\n",
    "epoch_acc = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch in test_iterator:\n",
    "\n",
    "        predictions = model(batch.review_text).squeeze(1)\n",
    "\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        rounded_preds = torch.round(torch.sigmoid(predictions))\n",
    "        \n",
    "        correct = (rounded_preds == batch.label).float() \n",
    "        acc = correct.sum() / len(correct)\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "test_loss = epoch_loss / len(test_iterator)\n",
    "test_acc  = epoch_acc / len(test_iterator)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}% |')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
